{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS6900.ipynb","provenance":[{"file_id":"18c_Wu2obu5JvYF1nT6aON4IskUvKx-t4","timestamp":1650756871039}],"collapsed_sections":[],"mount_file_id":"1KFZCAWUIJrnZfi-MpEfy2s2ZNTBf8WBp","authorship_tag":"ABX9TyPOVEMLJ77tt4rlHHR7KJK9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"id":"APDLU5XyWkPq","executionInfo":{"status":"ok","timestamp":1652660092272,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}}},"outputs":[],"source":["import os \n","os.chdir(\"/content/drive/MyDrive/CS690/BayesianPyTorch\")"]},{"cell_type":"code","source":["!python main_frequentist.py --net_type alexnet --dataset MNIST"],"metadata":{"id":"3JWopQPybBEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651151482342,"user_tz":240,"elapsed":20919,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"b8192fd1-9375-401d-cb0b-c813313edff3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100% 188/188 [00:08<00:00, 21.24it/s]\n","100% 47/47 [00:02<00:00, 21.79it/s]\n","Traceback (most recent call last):\n","  File \"main_frequentist.py\", line 198, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"main_frequentist.py\", line 170, in run\n","    valid_loss, valid_acc = validate_model(net, criterion, valid_loader)\n","  File \"main_frequentist.py\", line 99, in validate_model\n","    for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1195, in __iter__\n","    for obj in iterable:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1196, in _next_data\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1322, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["!python train_bayesian.py --net_type 3conv3fc "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyhaIFNAXFEl","executionInfo":{"status":"ok","timestamp":1651068817836,"user_tz":240,"elapsed":30629,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"4e0f9206-4b60-4818-cd23-73770c88e716"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"train_bayesian.py\", line 203, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"train_bayesian.py\", line 160, in run\n","    trainset, testset, inputs, outputs = data.getDataset(dataset)\n","TypeError: getDataset() missing 1 required positional argument: 'model'\n"]}]},{"cell_type":"code","source":["!python main_frequentist.py --net_type lenet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iu_2SHXvfdys","executionInfo":{"status":"ok","timestamp":1651473308153,"user_tz":240,"elapsed":826807,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"9f650bda-cd14-407f-eeee-e83e7b6f4348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100% 157/157 [00:05<00:00, 26.92it/s]\n","100% 40/40 [00:01<00:00, 27.47it/s]\n","Epoch: 1 \tTraining Loss: 2.0586 \tTraining Accuracy: 17.3360 \tValidation Loss: 1.8989 \tValidation Accuracy: 5.8140\n","Validation loss decreased (inf --> 1.898877).  Saving model ...\n","100% 157/157 [00:06<00:00, 24.59it/s]\n","100% 40/40 [00:01<00:00, 27.75it/s]\n","Epoch: 2 \tTraining Loss: 1.7937 \tTraining Accuracy: 26.5440 \tValidation Loss: 1.7081 \tValidation Accuracy: 7.3560\n","Validation loss decreased (1.898877 --> 1.708077).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.75it/s]\n","100% 40/40 [00:01<00:00, 26.98it/s]\n","Epoch: 3 \tTraining Loss: 1.6705 \tTraining Accuracy: 30.3960 \tValidation Loss: 1.6466 \tValidation Accuracy: 8.0360\n","Validation loss decreased (1.708077 --> 1.646580).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.06it/s]\n","100% 40/40 [00:01<00:00, 26.79it/s]\n","Epoch: 4 \tTraining Loss: 1.5836 \tTraining Accuracy: 33.3700 \tValidation Loss: 1.5732 \tValidation Accuracy: 8.6240\n","Validation loss decreased (1.646580 --> 1.573190).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.51it/s]\n","100% 40/40 [00:01<00:00, 27.60it/s]\n","Epoch: 5 \tTraining Loss: 1.5082 \tTraining Accuracy: 35.9440 \tValidation Loss: 1.4907 \tValidation Accuracy: 9.2000\n","Validation loss decreased (1.573190 --> 1.490682).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.31it/s]\n","100% 40/40 [00:01<00:00, 27.57it/s]\n","Epoch: 6 \tTraining Loss: 1.4495 \tTraining Accuracy: 37.7800 \tValidation Loss: 1.4265 \tValidation Accuracy: 9.5880\n","Validation loss decreased (1.490682 --> 1.426538).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.87it/s]\n","100% 40/40 [00:01<00:00, 26.73it/s]\n","Epoch: 7 \tTraining Loss: 1.4094 \tTraining Accuracy: 39.1060 \tValidation Loss: 1.3954 \tValidation Accuracy: 9.8700\n","Validation loss decreased (1.426538 --> 1.395445).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.00it/s]\n","100% 40/40 [00:01<00:00, 27.59it/s]\n","Epoch: 8 \tTraining Loss: 1.3823 \tTraining Accuracy: 40.2060 \tValidation Loss: 1.3877 \tValidation Accuracy: 9.8620\n","Validation loss decreased (1.395445 --> 1.387745).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.72it/s]\n","100% 40/40 [00:01<00:00, 28.29it/s]\n","Epoch: 9 \tTraining Loss: 1.3579 \tTraining Accuracy: 40.9420 \tValidation Loss: 1.3568 \tValidation Accuracy: 10.2360\n","Validation loss decreased (1.387745 --> 1.356800).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.91it/s]\n","100% 40/40 [00:01<00:00, 27.17it/s]\n","Epoch: 10 \tTraining Loss: 1.3157 \tTraining Accuracy: 42.1800 \tValidation Loss: 1.3896 \tValidation Accuracy: 10.1120\n","100% 157/157 [00:05<00:00, 26.81it/s]\n","100% 40/40 [00:01<00:00, 27.17it/s]\n","Epoch: 11 \tTraining Loss: 1.2939 \tTraining Accuracy: 43.1660 \tValidation Loss: 1.3097 \tValidation Accuracy: 10.6180\n","Validation loss decreased (1.356800 --> 1.309730).  Saving model ...\n","100% 157/157 [00:06<00:00, 25.06it/s]\n","100% 40/40 [00:01<00:00, 27.05it/s]\n","Epoch: 12 \tTraining Loss: 1.2749 \tTraining Accuracy: 43.4000 \tValidation Loss: 1.3317 \tValidation Accuracy: 10.4440\n","100% 157/157 [00:05<00:00, 27.07it/s]\n","100% 40/40 [00:01<00:00, 27.61it/s]\n","Epoch: 13 \tTraining Loss: 1.2524 \tTraining Accuracy: 44.3400 \tValidation Loss: 1.3451 \tValidation Accuracy: 10.2880\n","100% 157/157 [00:05<00:00, 27.22it/s]\n","100% 40/40 [00:01<00:00, 27.55it/s]\n","Epoch: 14 \tTraining Loss: 1.2304 \tTraining Accuracy: 45.1260 \tValidation Loss: 1.2868 \tValidation Accuracy: 10.7220\n","Validation loss decreased (1.309730 --> 1.286849).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.87it/s]\n","100% 40/40 [00:01<00:00, 26.63it/s]\n","Epoch: 15 \tTraining Loss: 1.2178 \tTraining Accuracy: 45.1420 \tValidation Loss: 1.2460 \tValidation Accuracy: 11.0320\n","Validation loss decreased (1.286849 --> 1.246003).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.99it/s]\n","100% 40/40 [00:01<00:00, 27.45it/s]\n","Epoch: 16 \tTraining Loss: 1.1937 \tTraining Accuracy: 46.0780 \tValidation Loss: 1.2346 \tValidation Accuracy: 11.0780\n","Validation loss decreased (1.246003 --> 1.234603).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.61it/s]\n","100% 40/40 [00:01<00:00, 27.40it/s]\n","Epoch: 17 \tTraining Loss: 1.1814 \tTraining Accuracy: 46.6100 \tValidation Loss: 1.2406 \tValidation Accuracy: 11.0860\n","100% 157/157 [00:05<00:00, 27.26it/s]\n","100% 40/40 [00:01<00:00, 27.48it/s]\n","Epoch: 18 \tTraining Loss: 1.1672 \tTraining Accuracy: 46.9180 \tValidation Loss: 1.2454 \tValidation Accuracy: 11.1660\n","100% 157/157 [00:05<00:00, 26.49it/s]\n","100% 40/40 [00:01<00:00, 26.50it/s]\n","Epoch: 19 \tTraining Loss: 1.1499 \tTraining Accuracy: 47.3720 \tValidation Loss: 1.2290 \tValidation Accuracy: 11.2840\n","Validation loss decreased (1.234603 --> 1.228963).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.04it/s]\n","100% 40/40 [00:01<00:00, 27.10it/s]\n","Epoch: 20 \tTraining Loss: 1.1400 \tTraining Accuracy: 47.6680 \tValidation Loss: 1.2542 \tValidation Accuracy: 11.1020\n","100% 157/157 [00:05<00:00, 27.13it/s]\n","100% 40/40 [00:01<00:00, 26.52it/s]\n","Epoch: 21 \tTraining Loss: 1.1250 \tTraining Accuracy: 48.0940 \tValidation Loss: 1.2053 \tValidation Accuracy: 11.3160\n","Validation loss decreased (1.228963 --> 1.205333).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.13it/s]\n","100% 40/40 [00:01<00:00, 26.88it/s]\n","Epoch: 22 \tTraining Loss: 1.1100 \tTraining Accuracy: 48.3300 \tValidation Loss: 1.2299 \tValidation Accuracy: 11.4820\n","100% 157/157 [00:05<00:00, 26.86it/s]\n","100% 40/40 [00:01<00:00, 27.23it/s]\n","Epoch: 23 \tTraining Loss: 1.0996 \tTraining Accuracy: 48.6880 \tValidation Loss: 1.1882 \tValidation Accuracy: 11.5400\n","Validation loss decreased (1.205333 --> 1.188225).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.20it/s]\n","100% 40/40 [00:01<00:00, 27.23it/s]\n","Epoch: 24 \tTraining Loss: 1.0816 \tTraining Accuracy: 49.2860 \tValidation Loss: 1.1826 \tValidation Accuracy: 11.6400\n","Validation loss decreased (1.188225 --> 1.182627).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.91it/s]\n","100% 40/40 [00:01<00:00, 26.65it/s]\n","Epoch: 25 \tTraining Loss: 1.0812 \tTraining Accuracy: 49.3620 \tValidation Loss: 1.1948 \tValidation Accuracy: 11.5140\n","100% 157/157 [00:05<00:00, 26.89it/s]\n","100% 40/40 [00:01<00:00, 26.36it/s]\n","Epoch: 26 \tTraining Loss: 1.0636 \tTraining Accuracy: 49.7580 \tValidation Loss: 1.1802 \tValidation Accuracy: 11.6140\n","Validation loss decreased (1.182627 --> 1.180191).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.04it/s]\n","100% 40/40 [00:01<00:00, 26.73it/s]\n","Epoch: 27 \tTraining Loss: 1.0546 \tTraining Accuracy: 49.9860 \tValidation Loss: 1.1755 \tValidation Accuracy: 11.5740\n","Validation loss decreased (1.180191 --> 1.175506).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.14it/s]\n","100% 40/40 [00:01<00:00, 27.47it/s]\n","Epoch: 28 \tTraining Loss: 1.0390 \tTraining Accuracy: 50.4560 \tValidation Loss: 1.1837 \tValidation Accuracy: 11.7520\n","100% 157/157 [00:05<00:00, 26.55it/s]\n","100% 40/40 [00:01<00:00, 26.43it/s]\n","Epoch: 29 \tTraining Loss: 1.0207 \tTraining Accuracy: 51.0360 \tValidation Loss: 1.1936 \tValidation Accuracy: 11.6160\n","100% 157/157 [00:05<00:00, 26.98it/s]\n","100% 40/40 [00:01<00:00, 27.49it/s]\n","Epoch: 30 \tTraining Loss: 1.0154 \tTraining Accuracy: 51.2400 \tValidation Loss: 1.1471 \tValidation Accuracy: 11.9920\n","Validation loss decreased (1.175506 --> 1.147105).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.99it/s]\n","100% 40/40 [00:01<00:00, 26.36it/s]\n","Epoch: 31 \tTraining Loss: 1.0079 \tTraining Accuracy: 51.4400 \tValidation Loss: 1.1771 \tValidation Accuracy: 11.7420\n","100% 157/157 [00:05<00:00, 27.23it/s]\n","100% 40/40 [00:01<00:00, 27.41it/s]\n","Epoch: 32 \tTraining Loss: 0.9938 \tTraining Accuracy: 51.9280 \tValidation Loss: 1.1507 \tValidation Accuracy: 12.0440\n","100% 157/157 [00:05<00:00, 26.84it/s]\n","100% 40/40 [00:01<00:00, 26.73it/s]\n","Epoch: 33 \tTraining Loss: 0.9799 \tTraining Accuracy: 52.1820 \tValidation Loss: 1.1605 \tValidation Accuracy: 12.0000\n","100% 157/157 [00:05<00:00, 26.73it/s]\n","100% 40/40 [00:01<00:00, 27.43it/s]\n","Epoch: 34 \tTraining Loss: 0.9753 \tTraining Accuracy: 52.4020 \tValidation Loss: 1.1767 \tValidation Accuracy: 11.7240\n","100% 157/157 [00:06<00:00, 25.20it/s]\n","100% 40/40 [00:01<00:00, 26.71it/s]\n","Epoch: 35 \tTraining Loss: 0.9760 \tTraining Accuracy: 52.4580 \tValidation Loss: 1.1526 \tValidation Accuracy: 11.9940\n","100% 157/157 [00:05<00:00, 27.29it/s]\n","100% 40/40 [00:01<00:00, 26.72it/s]\n","Epoch: 36 \tTraining Loss: 0.9573 \tTraining Accuracy: 53.0540 \tValidation Loss: 1.1826 \tValidation Accuracy: 11.8380\n","100% 157/157 [00:05<00:00, 26.86it/s]\n","100% 40/40 [00:01<00:00, 27.38it/s]\n","Epoch 00037: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch: 37 \tTraining Loss: 0.9412 \tTraining Accuracy: 53.3600 \tValidation Loss: 1.1482 \tValidation Accuracy: 12.0580\n","100% 157/157 [00:05<00:00, 27.11it/s]\n","100% 40/40 [00:01<00:00, 27.00it/s]\n","Epoch: 38 \tTraining Loss: 0.8874 \tTraining Accuracy: 55.0320 \tValidation Loss: 1.1280 \tValidation Accuracy: 12.2620\n","Validation loss decreased (1.147105 --> 1.128005).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.09it/s]\n","100% 40/40 [00:01<00:00, 26.90it/s]\n","Epoch: 39 \tTraining Loss: 0.8781 \tTraining Accuracy: 55.4040 \tValidation Loss: 1.1164 \tValidation Accuracy: 12.2640\n","Validation loss decreased (1.128005 --> 1.116406).  Saving model ...\n","100% 157/157 [00:05<00:00, 26.94it/s]\n","100% 40/40 [00:01<00:00, 26.73it/s]\n","Epoch: 40 \tTraining Loss: 0.8755 \tTraining Accuracy: 55.3360 \tValidation Loss: 1.1298 \tValidation Accuracy: 12.2600\n","100% 157/157 [00:05<00:00, 27.01it/s]\n","100% 40/40 [00:01<00:00, 26.57it/s]\n","Epoch: 41 \tTraining Loss: 0.8730 \tTraining Accuracy: 55.5180 \tValidation Loss: 1.1341 \tValidation Accuracy: 12.2680\n","100% 157/157 [00:05<00:00, 26.79it/s]\n","100% 40/40 [00:01<00:00, 26.91it/s]\n","Epoch: 42 \tTraining Loss: 0.8713 \tTraining Accuracy: 55.5060 \tValidation Loss: 1.1217 \tValidation Accuracy: 12.2700\n","100% 157/157 [00:05<00:00, 27.21it/s]\n","100% 40/40 [00:01<00:00, 26.63it/s]\n","Epoch: 43 \tTraining Loss: 0.8686 \tTraining Accuracy: 55.5000 \tValidation Loss: 1.1373 \tValidation Accuracy: 12.2800\n","100% 157/157 [00:05<00:00, 27.14it/s]\n","100% 40/40 [00:01<00:00, 28.33it/s]\n","Epoch: 44 \tTraining Loss: 0.8691 \tTraining Accuracy: 55.6840 \tValidation Loss: 1.1307 \tValidation Accuracy: 12.2380\n","100% 157/157 [00:05<00:00, 26.84it/s]\n","100% 40/40 [00:01<00:00, 26.84it/s]\n","Epoch: 45 \tTraining Loss: 0.8661 \tTraining Accuracy: 55.7220 \tValidation Loss: 1.1331 \tValidation Accuracy: 12.2520\n","100% 157/157 [00:05<00:00, 27.12it/s]\n","100% 40/40 [00:01<00:00, 27.48it/s]\n","Epoch 00046: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch: 46 \tTraining Loss: 0.8653 \tTraining Accuracy: 55.6100 \tValidation Loss: 1.1304 \tValidation Accuracy: 12.2500\n","100% 157/157 [00:05<00:00, 27.22it/s]\n","100% 40/40 [00:01<00:00, 26.93it/s]\n","Epoch: 47 \tTraining Loss: 0.8574 \tTraining Accuracy: 55.9840 \tValidation Loss: 1.1145 \tValidation Accuracy: 12.2740\n","Validation loss decreased (1.116406 --> 1.114514).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.30it/s]\n","100% 40/40 [00:01<00:00, 26.77it/s]\n","Epoch: 48 \tTraining Loss: 0.8557 \tTraining Accuracy: 55.9960 \tValidation Loss: 1.1241 \tValidation Accuracy: 12.2620\n","100% 157/157 [00:05<00:00, 26.90it/s]\n","100% 40/40 [00:01<00:00, 26.62it/s]\n","Epoch: 49 \tTraining Loss: 0.8558 \tTraining Accuracy: 55.9980 \tValidation Loss: 1.1296 \tValidation Accuracy: 12.2700\n","100% 157/157 [00:05<00:00, 27.09it/s]\n","100% 40/40 [00:01<00:00, 27.30it/s]\n","Epoch: 50 \tTraining Loss: 0.8563 \tTraining Accuracy: 55.9460 \tValidation Loss: 1.1173 \tValidation Accuracy: 12.2840\n","100% 157/157 [00:05<00:00, 27.08it/s]\n","100% 40/40 [00:01<00:00, 27.06it/s]\n","Epoch: 51 \tTraining Loss: 0.8566 \tTraining Accuracy: 55.9920 \tValidation Loss: 1.1328 \tValidation Accuracy: 12.2740\n","100% 157/157 [00:05<00:00, 27.18it/s]\n","100% 40/40 [00:01<00:00, 26.91it/s]\n","Epoch: 52 \tTraining Loss: 0.8551 \tTraining Accuracy: 56.0000 \tValidation Loss: 1.1415 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.03it/s]\n","100% 40/40 [00:01<00:00, 27.42it/s]\n","Epoch: 53 \tTraining Loss: 0.8556 \tTraining Accuracy: 55.9980 \tValidation Loss: 1.1324 \tValidation Accuracy: 12.2740\n","100% 157/157 [00:05<00:00, 26.79it/s]\n","100% 40/40 [00:01<00:00, 26.86it/s]\n","Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch: 54 \tTraining Loss: 0.8569 \tTraining Accuracy: 56.0080 \tValidation Loss: 1.1317 \tValidation Accuracy: 12.2920\n","100% 157/157 [00:05<00:00, 27.36it/s]\n","100% 40/40 [00:01<00:00, 26.79it/s]\n","Epoch: 55 \tTraining Loss: 0.8550 \tTraining Accuracy: 56.0420 \tValidation Loss: 1.1184 \tValidation Accuracy: 12.2960\n","100% 157/157 [00:05<00:00, 26.99it/s]\n","100% 40/40 [00:01<00:00, 26.72it/s]\n","Epoch: 56 \tTraining Loss: 0.8537 \tTraining Accuracy: 56.0560 \tValidation Loss: 1.1266 \tValidation Accuracy: 12.2900\n","100% 157/157 [00:05<00:00, 26.82it/s]\n","100% 40/40 [00:01<00:00, 27.83it/s]\n","Epoch: 57 \tTraining Loss: 0.8543 \tTraining Accuracy: 56.0660 \tValidation Loss: 1.1202 \tValidation Accuracy: 12.2840\n","100% 157/157 [00:05<00:00, 27.35it/s]\n","100% 40/40 [00:01<00:00, 27.18it/s]\n","Epoch: 58 \tTraining Loss: 0.8542 \tTraining Accuracy: 56.0700 \tValidation Loss: 1.1281 \tValidation Accuracy: 12.2840\n","100% 157/157 [00:05<00:00, 27.20it/s]\n","100% 40/40 [00:01<00:00, 27.39it/s]\n","Epoch: 59 \tTraining Loss: 0.8543 \tTraining Accuracy: 56.0800 \tValidation Loss: 1.1174 \tValidation Accuracy: 12.2820\n","100% 157/157 [00:05<00:00, 27.15it/s]\n","100% 40/40 [00:01<00:00, 27.31it/s]\n","Epoch: 60 \tTraining Loss: 0.8545 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1225 \tValidation Accuracy: 12.2800\n","100% 157/157 [00:05<00:00, 26.64it/s]\n","100% 40/40 [00:01<00:00, 26.44it/s]\n","Epoch 00061: reducing learning rate of group 0 to 1.0000e-07.\n","Epoch: 61 \tTraining Loss: 0.8542 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1340 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.00it/s]\n","100% 40/40 [00:01<00:00, 27.71it/s]\n","Epoch: 62 \tTraining Loss: 0.8541 \tTraining Accuracy: 56.0740 \tValidation Loss: 1.1386 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.82it/s]\n","100% 40/40 [00:01<00:00, 27.31it/s]\n","Epoch: 63 \tTraining Loss: 0.8547 \tTraining Accuracy: 56.0760 \tValidation Loss: 1.1408 \tValidation Accuracy: 12.2720\n","100% 157/157 [00:05<00:00, 27.00it/s]\n","100% 40/40 [00:01<00:00, 26.92it/s]\n","Epoch: 64 \tTraining Loss: 0.8547 \tTraining Accuracy: 56.0920 \tValidation Loss: 1.1250 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 26.77it/s]\n","100% 40/40 [00:01<00:00, 26.46it/s]\n","Epoch: 65 \tTraining Loss: 0.8540 \tTraining Accuracy: 56.0820 \tValidation Loss: 1.1172 \tValidation Accuracy: 12.2740\n","100% 157/157 [00:05<00:00, 27.14it/s]\n","100% 40/40 [00:01<00:00, 26.73it/s]\n","Epoch: 66 \tTraining Loss: 0.8544 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1296 \tValidation Accuracy: 12.2740\n","100% 157/157 [00:05<00:00, 27.21it/s]\n","100% 40/40 [00:01<00:00, 26.95it/s]\n","Epoch: 67 \tTraining Loss: 0.8536 \tTraining Accuracy: 56.0860 \tValidation Loss: 1.1238 \tValidation Accuracy: 12.2740\n","100% 157/157 [00:05<00:00, 27.32it/s]\n","100% 40/40 [00:01<00:00, 26.80it/s]\n","Epoch 00068: reducing learning rate of group 0 to 1.0000e-08.\n","Epoch: 68 \tTraining Loss: 0.8539 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1313 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 26.80it/s]\n","100% 40/40 [00:01<00:00, 27.20it/s]\n","Epoch: 69 \tTraining Loss: 0.8546 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1200 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 27.34it/s]\n","100% 40/40 [00:01<00:00, 26.92it/s]\n","Epoch: 70 \tTraining Loss: 0.8545 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1282 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 27.18it/s]\n","100% 40/40 [00:01<00:00, 27.21it/s]\n","Epoch: 71 \tTraining Loss: 0.8546 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1292 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 27.36it/s]\n","100% 40/40 [00:01<00:00, 27.35it/s]\n","Epoch: 72 \tTraining Loss: 0.8543 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1318 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 26.81it/s]\n","100% 40/40 [00:01<00:00, 27.12it/s]\n","Epoch: 73 \tTraining Loss: 0.8540 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1188 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 27.14it/s]\n","100% 40/40 [00:01<00:00, 27.29it/s]\n","Epoch: 74 \tTraining Loss: 0.8536 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1301 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.83it/s]\n","100% 40/40 [00:01<00:00, 27.08it/s]\n","Epoch: 75 \tTraining Loss: 0.8542 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1155 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.19it/s]\n","100% 40/40 [00:01<00:00, 26.94it/s]\n","Epoch: 76 \tTraining Loss: 0.8550 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1313 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.78it/s]\n","100% 40/40 [00:01<00:00, 27.43it/s]\n","Epoch: 77 \tTraining Loss: 0.8545 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1274 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.28it/s]\n","100% 40/40 [00:01<00:00, 26.67it/s]\n","Epoch: 78 \tTraining Loss: 0.8549 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1243 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.11it/s]\n","100% 40/40 [00:01<00:00, 27.52it/s]\n","Epoch: 79 \tTraining Loss: 0.8544 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1196 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.16it/s]\n","100% 40/40 [00:01<00:00, 26.57it/s]\n","Epoch: 80 \tTraining Loss: 0.8528 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1305 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.26it/s]\n","100% 40/40 [00:01<00:00, 27.00it/s]\n","Epoch: 81 \tTraining Loss: 0.8530 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1235 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.94it/s]\n","100% 40/40 [00:01<00:00, 26.84it/s]\n","Epoch: 82 \tTraining Loss: 0.8538 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1255 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.26it/s]\n","100% 40/40 [00:01<00:00, 27.35it/s]\n","Epoch: 83 \tTraining Loss: 0.8554 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1292 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.22it/s]\n","100% 40/40 [00:01<00:00, 26.89it/s]\n","Epoch: 84 \tTraining Loss: 0.8545 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1333 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.90it/s]\n","100% 40/40 [00:01<00:00, 26.95it/s]\n","Epoch: 85 \tTraining Loss: 0.8551 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1407 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.12it/s]\n","100% 40/40 [00:01<00:00, 27.52it/s]\n","Epoch: 86 \tTraining Loss: 0.8539 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1127 \tValidation Accuracy: 12.2780\n","Validation loss decreased (1.114514 --> 1.112689).  Saving model ...\n","100% 157/157 [00:05<00:00, 27.28it/s]\n","100% 40/40 [00:01<00:00, 27.53it/s]\n","Epoch: 87 \tTraining Loss: 0.8550 \tTraining Accuracy: 56.0840 \tValidation Loss: 1.1199 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.31it/s]\n","100% 40/40 [00:01<00:00, 27.02it/s]\n","Epoch: 88 \tTraining Loss: 0.8539 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1212 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.40it/s]\n","100% 40/40 [00:01<00:00, 27.16it/s]\n","Epoch: 89 \tTraining Loss: 0.8545 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1209 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 27.08it/s]\n","100% 40/40 [00:01<00:00, 27.05it/s]\n","Epoch: 90 \tTraining Loss: 0.8537 \tTraining Accuracy: 56.0860 \tValidation Loss: 1.1154 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.27it/s]\n","100% 40/40 [00:01<00:00, 27.13it/s]\n","Epoch: 91 \tTraining Loss: 0.8535 \tTraining Accuracy: 56.0860 \tValidation Loss: 1.1322 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 27.11it/s]\n","100% 40/40 [00:01<00:00, 27.01it/s]\n","Epoch: 92 \tTraining Loss: 0.8539 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1226 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:05<00:00, 26.76it/s]\n","100% 40/40 [00:01<00:00, 26.60it/s]\n","Epoch: 93 \tTraining Loss: 0.8543 \tTraining Accuracy: 56.0900 \tValidation Loss: 1.1263 \tValidation Accuracy: 12.2760\n","100% 157/157 [00:06<00:00, 23.95it/s]\n","100% 40/40 [00:02<00:00, 19.18it/s]\n","Epoch: 94 \tTraining Loss: 0.8541 \tTraining Accuracy: 56.0900 \tValidation Loss: 1.1136 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.35it/s]\n","100% 40/40 [00:01<00:00, 27.27it/s]\n","Epoch: 95 \tTraining Loss: 0.8555 \tTraining Accuracy: 56.0860 \tValidation Loss: 1.1254 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.81it/s]\n","100% 40/40 [00:01<00:00, 26.56it/s]\n","Epoch: 96 \tTraining Loss: 0.8541 \tTraining Accuracy: 56.0900 \tValidation Loss: 1.1271 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.92it/s]\n","100% 40/40 [00:01<00:00, 27.18it/s]\n","Epoch: 97 \tTraining Loss: 0.8540 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1286 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.44it/s]\n","100% 40/40 [00:01<00:00, 27.94it/s]\n","Epoch: 98 \tTraining Loss: 0.8547 \tTraining Accuracy: 56.0900 \tValidation Loss: 1.1313 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.21it/s]\n","100% 40/40 [00:01<00:00, 27.07it/s]\n","Epoch: 99 \tTraining Loss: 0.8539 \tTraining Accuracy: 56.0900 \tValidation Loss: 1.1199 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.17it/s]\n","100% 40/40 [00:01<00:00, 26.47it/s]\n","Epoch: 100 \tTraining Loss: 0.8538 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1202 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.65it/s]\n","100% 40/40 [00:01<00:00, 27.15it/s]\n","Epoch: 101 \tTraining Loss: 0.8560 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1229 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.03it/s]\n","100% 40/40 [00:01<00:00, 27.60it/s]\n","Epoch: 102 \tTraining Loss: 0.8533 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1311 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 26.59it/s]\n","100% 40/40 [00:01<00:00, 26.72it/s]\n","Epoch: 103 \tTraining Loss: 0.8555 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1284 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.16it/s]\n","100% 40/40 [00:01<00:00, 27.26it/s]\n","Epoch: 104 \tTraining Loss: 0.8546 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1135 \tValidation Accuracy: 12.2780\n","100% 157/157 [00:05<00:00, 27.06it/s]\n","100% 40/40 [00:01<00:00, 26.78it/s]\n","Epoch: 105 \tTraining Loss: 0.8533 \tTraining Accuracy: 56.0880 \tValidation Loss: 1.1177 \tValidation Accuracy: 12.2780\n","Traceback (most recent call last):\n","  File \"main_frequentist.py\", line 198, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"main_frequentist.py\", line 169, in run\n","    train_loss, train_acc = train_model(net, optimizer, criterion, train_loader)\n","  File \"main_frequentist.py\", line 51, in train_model\n","    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 368, in __iter__\n","    return self._get_iterator()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 314, in _get_iterator\n","    return _MultiProcessingDataLoaderIter(self)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 965, in __init__\n","    self._reset(loader, first_iter=True)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 996, in _reset\n","    self._try_put_index()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1230, in _try_put_index\n","    index = self._next_index()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in _next_index\n","    return next(self._sampler_iter)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\", line 226, in __iter__\n","    for idx in self.sampler:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\", line 143, in __iter__\n","    for i in torch.randperm(len(self.indices), generator=self.generator):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 704, in __iter__\n","    return iter(self.unbind(0))\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["!python main_bayesian.py --net_type  --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zG5NDzGqczJ9","executionInfo":{"status":"ok","timestamp":1651072748333,"user_tz":240,"elapsed":1005494,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"05b16c5b-ebc3-4c64-e728-42e8936815cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100% 157/157 [00:07<00:00, 20.55it/s]\n","100% 40/40 [00:01<00:00, 21.50it/s]\n","Epoch: 1 \tTraining Loss: 0.0003 \tTraining Accuracy: 12.0760 \tValidation Loss: 0.0000 \tValidation Accuracy: 4.2560\n","Validation loss decreased (inf --> 0.000043).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.66it/s]\n","100% 40/40 [00:01<00:00, 21.27it/s]\n","Epoch: 2 \tTraining Loss: 0.0000 \tTraining Accuracy: 17.5880 \tValidation Loss: 0.0000 \tValidation Accuracy: 4.8980\n","Validation loss decreased (0.000043 --> 0.000041).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.77it/s]\n","100% 40/40 [00:01<00:00, 21.67it/s]\n","Epoch: 3 \tTraining Loss: 0.0000 \tTraining Accuracy: 20.2080 \tValidation Loss: 0.0000 \tValidation Accuracy: 5.1460\n","Validation loss decreased (0.000041 --> 0.000040).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.46it/s]\n","100% 40/40 [00:01<00:00, 21.73it/s]\n","Epoch: 4 \tTraining Loss: 0.0000 \tTraining Accuracy: 23.1700 \tValidation Loss: 0.0000 \tValidation Accuracy: 6.3200\n","Validation loss decreased (0.000040 --> 0.000038).  Saving model ...\n","100% 157/157 [00:09<00:00, 17.23it/s]\n","100% 40/40 [00:02<00:00, 16.46it/s]\n","Epoch: 5 \tTraining Loss: 0.0000 \tTraining Accuracy: 26.7520 \tValidation Loss: 0.0000 \tValidation Accuracy: 6.7720\n","Validation loss decreased (0.000038 --> 0.000036).  Saving model ...\n","100% 157/157 [00:08<00:00, 17.96it/s]\n","100% 40/40 [00:02<00:00, 17.26it/s]\n","Epoch: 6 \tTraining Loss: 0.0000 \tTraining Accuracy: 29.0700 \tValidation Loss: 0.0000 \tValidation Accuracy: 7.3740\n","Validation loss decreased (0.000036 --> 0.000034).  Saving model ...\n","100% 157/157 [00:08<00:00, 17.88it/s]\n","100% 40/40 [00:01<00:00, 20.73it/s]\n","Epoch: 7 \tTraining Loss: 0.0000 \tTraining Accuracy: 30.5580 \tValidation Loss: 0.0000 \tValidation Accuracy: 7.3600\n","100% 157/157 [00:07<00:00, 20.60it/s]\n","100% 40/40 [00:01<00:00, 21.47it/s]\n","Epoch: 8 \tTraining Loss: 0.0000 \tTraining Accuracy: 32.1160 \tValidation Loss: 0.0000 \tValidation Accuracy: 8.0680\n","Validation loss decreased (0.000034 --> 0.000033).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.41it/s]\n","100% 40/40 [00:01<00:00, 21.38it/s]\n","Epoch: 9 \tTraining Loss: 0.0000 \tTraining Accuracy: 33.1640 \tValidation Loss: 0.0000 \tValidation Accuracy: 8.3520\n","Validation loss decreased (0.000033 --> 0.000033).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.19it/s]\n","100% 40/40 [00:01<00:00, 21.33it/s]\n","Epoch: 10 \tTraining Loss: 0.0000 \tTraining Accuracy: 34.0080 \tValidation Loss: 0.0000 \tValidation Accuracy: 8.3560\n","100% 157/157 [00:07<00:00, 20.46it/s]\n","100% 40/40 [00:01<00:00, 21.97it/s]\n","Epoch: 11 \tTraining Loss: 0.0000 \tTraining Accuracy: 35.1660 \tValidation Loss: 0.0000 \tValidation Accuracy: 7.9920\n","100% 157/157 [00:08<00:00, 19.08it/s]\n","100% 40/40 [00:01<00:00, 21.79it/s]\n","Epoch: 12 \tTraining Loss: 0.0000 \tTraining Accuracy: 35.7940 \tValidation Loss: 0.0000 \tValidation Accuracy: 8.7180\n","Validation loss decreased (0.000033 --> 0.000031).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.00it/s]\n","100% 40/40 [00:01<00:00, 21.40it/s]\n","Epoch: 13 \tTraining Loss: 0.0000 \tTraining Accuracy: 36.4900 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.3200\n","Validation loss decreased (0.000031 --> 0.000030).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.80it/s]\n","100% 40/40 [00:01<00:00, 21.48it/s]\n","Epoch: 14 \tTraining Loss: 0.0000 \tTraining Accuracy: 37.4300 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.1280\n","100% 157/157 [00:07<00:00, 20.77it/s]\n","100% 40/40 [00:01<00:00, 21.47it/s]\n","Epoch: 15 \tTraining Loss: 0.0000 \tTraining Accuracy: 38.1400 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.5600\n","Validation loss decreased (0.000030 --> 0.000029).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.77it/s]\n","100% 40/40 [00:01<00:00, 21.39it/s]\n","Epoch: 16 \tTraining Loss: 0.0000 \tTraining Accuracy: 38.9820 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.7000\n","Validation loss decreased (0.000029 --> 0.000029).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.40it/s]\n","100% 40/40 [00:02<00:00, 18.46it/s]\n","Epoch: 17 \tTraining Loss: 0.0000 \tTraining Accuracy: 39.6040 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.6560\n","100% 157/157 [00:07<00:00, 20.98it/s]\n","100% 40/40 [00:01<00:00, 21.68it/s]\n","Epoch: 18 \tTraining Loss: 0.0000 \tTraining Accuracy: 39.9700 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.8660\n","Validation loss decreased (0.000029 --> 0.000029).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.64it/s]\n","100% 40/40 [00:01<00:00, 21.80it/s]\n","Epoch: 19 \tTraining Loss: 0.0000 \tTraining Accuracy: 40.4660 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.9960\n","Validation loss decreased (0.000029 --> 0.000028).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.72it/s]\n","100% 40/40 [00:01<00:00, 21.82it/s]\n","Epoch: 20 \tTraining Loss: 0.0000 \tTraining Accuracy: 41.1400 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.1300\n","Validation loss decreased (0.000028 --> 0.000028).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.01it/s]\n","100% 40/40 [00:01<00:00, 22.08it/s]\n","Epoch: 21 \tTraining Loss: 0.0000 \tTraining Accuracy: 41.4640 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.3580\n","Validation loss decreased (0.000028 --> 0.000027).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.51it/s]\n","100% 40/40 [00:01<00:00, 21.98it/s]\n","Epoch: 22 \tTraining Loss: 0.0000 \tTraining Accuracy: 41.9620 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.1740\n","100% 157/157 [00:07<00:00, 20.85it/s]\n","100% 40/40 [00:01<00:00, 21.08it/s]\n","Epoch: 23 \tTraining Loss: 0.0000 \tTraining Accuracy: 42.1260 \tValidation Loss: 0.0000 \tValidation Accuracy: 9.6180\n","100% 157/157 [00:07<00:00, 20.96it/s]\n","100% 40/40 [00:01<00:00, 21.47it/s]\n","Epoch: 24 \tTraining Loss: 0.0000 \tTraining Accuracy: 42.7140 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.5540\n","Validation loss decreased (0.000027 --> 0.000027).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.60it/s]\n","100% 40/40 [00:01<00:00, 21.50it/s]\n","Epoch: 25 \tTraining Loss: 0.0000 \tTraining Accuracy: 42.7660 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.0920\n","100% 157/157 [00:07<00:00, 20.93it/s]\n","100% 40/40 [00:01<00:00, 22.06it/s]\n","Epoch: 26 \tTraining Loss: 0.0000 \tTraining Accuracy: 43.7960 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.7100\n","Validation loss decreased (0.000027 --> 0.000026).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.86it/s]\n","100% 40/40 [00:01<00:00, 21.93it/s]\n","Epoch: 27 \tTraining Loss: 0.0000 \tTraining Accuracy: 43.6000 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.1200\n","100% 157/157 [00:07<00:00, 21.05it/s]\n","100% 40/40 [00:01<00:00, 21.63it/s]\n","Epoch: 28 \tTraining Loss: 0.0000 \tTraining Accuracy: 44.1320 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.6320\n","Validation loss decreased (0.000026 --> 0.000026).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.75it/s]\n","100% 40/40 [00:01<00:00, 21.39it/s]\n","Epoch: 29 \tTraining Loss: 0.0000 \tTraining Accuracy: 44.8220 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.7960\n","100% 157/157 [00:07<00:00, 20.71it/s]\n","100% 40/40 [00:01<00:00, 21.77it/s]\n","Epoch: 30 \tTraining Loss: 0.0000 \tTraining Accuracy: 44.8020 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.4240\n","100% 157/157 [00:07<00:00, 20.93it/s]\n","100% 40/40 [00:01<00:00, 21.33it/s]\n","Epoch: 31 \tTraining Loss: 0.0000 \tTraining Accuracy: 45.7180 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.7100\n","100% 157/157 [00:07<00:00, 20.78it/s]\n","100% 40/40 [00:01<00:00, 21.77it/s]\n","Epoch: 32 \tTraining Loss: 0.0000 \tTraining Accuracy: 45.6980 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.5580\n","100% 157/157 [00:07<00:00, 20.82it/s]\n","100% 40/40 [00:01<00:00, 22.06it/s]\n","Epoch: 33 \tTraining Loss: 0.0000 \tTraining Accuracy: 45.5520 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.9860\n","Validation loss decreased (0.000026 --> 0.000026).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.67it/s]\n","100% 40/40 [00:01<00:00, 21.12it/s]\n","Epoch: 34 \tTraining Loss: 0.0000 \tTraining Accuracy: 46.7780 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.9080\n","100% 157/157 [00:07<00:00, 20.59it/s]\n","100% 40/40 [00:01<00:00, 21.97it/s]\n","Epoch: 35 \tTraining Loss: 0.0000 \tTraining Accuracy: 46.6700 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.0100\n","100% 157/157 [00:07<00:00, 20.72it/s]\n","100% 40/40 [00:01<00:00, 21.54it/s]\n","Epoch: 36 \tTraining Loss: 0.0000 \tTraining Accuracy: 47.6080 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.1960\n","Validation loss decreased (0.000026 --> 0.000025).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.83it/s]\n","100% 40/40 [00:01<00:00, 21.46it/s]\n","Epoch: 37 \tTraining Loss: 0.0000 \tTraining Accuracy: 47.6900 \tValidation Loss: 0.0000 \tValidation Accuracy: 10.9200\n","100% 157/157 [00:07<00:00, 20.41it/s]\n","100% 40/40 [00:01<00:00, 21.05it/s]\n","Epoch: 38 \tTraining Loss: 0.0000 \tTraining Accuracy: 48.0480 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.3900\n","Validation loss decreased (0.000025 --> 0.000024).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.70it/s]\n","100% 40/40 [00:01<00:00, 21.26it/s]\n","Epoch: 39 \tTraining Loss: 0.0000 \tTraining Accuracy: 48.1620 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.1680\n","100% 157/157 [00:07<00:00, 20.25it/s]\n","100% 40/40 [00:01<00:00, 21.68it/s]\n","Epoch: 40 \tTraining Loss: 0.0000 \tTraining Accuracy: 48.1680 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.4340\n","Validation loss decreased (0.000024 --> 0.000024).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.67it/s]\n","100% 40/40 [00:01<00:00, 21.54it/s]\n","Epoch: 41 \tTraining Loss: 0.0000 \tTraining Accuracy: 49.0080 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.1440\n","100% 157/157 [00:07<00:00, 21.00it/s]\n","100% 40/40 [00:01<00:00, 21.60it/s]\n","Epoch: 42 \tTraining Loss: 0.0000 \tTraining Accuracy: 49.0940 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.3580\n","100% 157/157 [00:07<00:00, 21.26it/s]\n","100% 40/40 [00:01<00:00, 21.52it/s]\n","Epoch: 43 \tTraining Loss: 0.0000 \tTraining Accuracy: 49.8680 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.2900\n","100% 157/157 [00:07<00:00, 20.75it/s]\n","100% 40/40 [00:01<00:00, 22.03it/s]\n","Epoch: 44 \tTraining Loss: 0.0000 \tTraining Accuracy: 50.5640 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.3560\n","100% 157/157 [00:07<00:00, 20.78it/s]\n","100% 40/40 [00:01<00:00, 22.06it/s]\n","Epoch: 45 \tTraining Loss: 0.0000 \tTraining Accuracy: 49.9500 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.0600\n","100% 157/157 [00:07<00:00, 20.92it/s]\n","100% 40/40 [00:01<00:00, 21.94it/s]\n","Epoch: 46 \tTraining Loss: 0.0000 \tTraining Accuracy: 50.5980 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.8640\n","100% 157/157 [00:07<00:00, 20.88it/s]\n","100% 40/40 [00:01<00:00, 21.45it/s]\n","Epoch: 47 \tTraining Loss: 0.0000 \tTraining Accuracy: 51.1420 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.8920\n","Validation loss decreased (0.000024 --> 0.000023).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.56it/s]\n","100% 40/40 [00:01<00:00, 22.03it/s]\n","Epoch: 48 \tTraining Loss: 0.0000 \tTraining Accuracy: 51.3920 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.5100\n","100% 157/157 [00:07<00:00, 20.88it/s]\n","100% 40/40 [00:01<00:00, 21.64it/s]\n","Epoch: 49 \tTraining Loss: 0.0000 \tTraining Accuracy: 51.6760 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.8740\n","100% 157/157 [00:07<00:00, 20.56it/s]\n","100% 40/40 [00:01<00:00, 21.75it/s]\n","Epoch: 50 \tTraining Loss: 0.0000 \tTraining Accuracy: 52.1520 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.9400\n","100% 157/157 [00:07<00:00, 20.85it/s]\n","100% 40/40 [00:01<00:00, 22.16it/s]\n","Epoch: 51 \tTraining Loss: 0.0000 \tTraining Accuracy: 52.2660 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.0740\n","Validation loss decreased (0.000023 --> 0.000023).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.98it/s]\n","100% 40/40 [00:01<00:00, 21.94it/s]\n","Epoch: 52 \tTraining Loss: 0.0000 \tTraining Accuracy: 52.7500 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.9760\n","100% 157/157 [00:07<00:00, 20.69it/s]\n","100% 40/40 [00:01<00:00, 22.09it/s]\n","Epoch: 53 \tTraining Loss: 0.0000 \tTraining Accuracy: 52.7680 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.3360\n","Validation loss decreased (0.000023 --> 0.000022).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.79it/s]\n","100% 40/40 [00:01<00:00, 21.79it/s]\n","Epoch: 54 \tTraining Loss: 0.0000 \tTraining Accuracy: 53.2440 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.3640\n","100% 157/157 [00:07<00:00, 20.66it/s]\n","100% 40/40 [00:01<00:00, 22.26it/s]\n","Epoch: 55 \tTraining Loss: 0.0000 \tTraining Accuracy: 53.2260 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.5100\n","100% 157/157 [00:08<00:00, 19.62it/s]\n","100% 40/40 [00:01<00:00, 22.23it/s]\n","Epoch: 56 \tTraining Loss: 0.0000 \tTraining Accuracy: 53.3140 \tValidation Loss: 0.0000 \tValidation Accuracy: 11.6820\n","100% 157/157 [00:07<00:00, 20.80it/s]\n","100% 40/40 [00:01<00:00, 21.88it/s]\n","Epoch: 57 \tTraining Loss: 0.0000 \tTraining Accuracy: 53.6120 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.3740\n","100% 157/157 [00:07<00:00, 20.99it/s]\n","100% 40/40 [00:01<00:00, 21.73it/s]\n","Epoch: 58 \tTraining Loss: 0.0000 \tTraining Accuracy: 54.1560 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.1660\n","100% 157/157 [00:07<00:00, 20.95it/s]\n","100% 40/40 [00:01<00:00, 21.97it/s]\n","Epoch: 59 \tTraining Loss: 0.0000 \tTraining Accuracy: 54.4040 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.2320\n","100% 157/157 [00:07<00:00, 20.84it/s]\n","100% 40/40 [00:01<00:00, 21.88it/s]\n","Epoch 00060: reducing learning rate of group 0 to 1.0000e-03.\n","Epoch: 60 \tTraining Loss: 0.0000 \tTraining Accuracy: 55.0320 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.3560\n","100% 157/157 [00:07<00:00, 20.76it/s]\n","100% 40/40 [00:01<00:00, 21.58it/s]\n","Epoch: 61 \tTraining Loss: 0.0000 \tTraining Accuracy: 58.1340 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0760\n","Validation loss decreased (0.000022 --> 0.000021).  Saving model ...\n","100% 157/157 [00:07<00:00, 20.77it/s]\n","100% 40/40 [00:01<00:00, 21.24it/s]\n","Epoch: 62 \tTraining Loss: 0.0000 \tTraining Accuracy: 58.8760 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0100\n","100% 157/157 [00:07<00:00, 20.43it/s]\n","100% 40/40 [00:01<00:00, 22.58it/s]\n","Epoch: 63 \tTraining Loss: 0.0000 \tTraining Accuracy: 59.4500 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.9500\n","100% 157/157 [00:07<00:00, 20.87it/s]\n","100% 40/40 [00:01<00:00, 22.15it/s]\n","Epoch: 64 \tTraining Loss: 0.0000 \tTraining Accuracy: 59.6820 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0000\n","100% 157/157 [00:07<00:00, 20.66it/s]\n","100% 40/40 [00:01<00:00, 21.40it/s]\n","Epoch: 65 \tTraining Loss: 0.0000 \tTraining Accuracy: 59.7980 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.9340\n","100% 157/157 [00:07<00:00, 20.78it/s]\n","100% 40/40 [00:01<00:00, 21.84it/s]\n","Epoch: 66 \tTraining Loss: 0.0000 \tTraining Accuracy: 60.0320 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.9840\n","100% 157/157 [00:07<00:00, 20.99it/s]\n","100% 40/40 [00:01<00:00, 22.00it/s]\n","Epoch: 67 \tTraining Loss: 0.0000 \tTraining Accuracy: 60.4340 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.9900\n","100% 157/157 [00:07<00:00, 21.05it/s]\n","100% 40/40 [00:01<00:00, 21.99it/s]\n","Epoch 00068: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch: 68 \tTraining Loss: 0.0000 \tTraining Accuracy: 60.3620 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.8860\n","100% 157/157 [00:07<00:00, 20.86it/s]\n","100% 40/40 [00:01<00:00, 21.92it/s]\n","Epoch: 69 \tTraining Loss: 0.0000 \tTraining Accuracy: 60.8260 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1240\n","100% 157/157 [00:07<00:00, 20.75it/s]\n","100% 40/40 [00:01<00:00, 21.69it/s]\n","Epoch: 70 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.1800 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1340\n","100% 157/157 [00:07<00:00, 21.00it/s]\n","100% 40/40 [00:01<00:00, 21.04it/s]\n","Epoch: 71 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.2720 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1020\n","100% 157/157 [00:07<00:00, 21.02it/s]\n","100% 40/40 [00:01<00:00, 21.65it/s]\n","Epoch: 72 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.2040 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0560\n","100% 157/157 [00:07<00:00, 20.90it/s]\n","100% 40/40 [00:01<00:00, 21.86it/s]\n","Epoch: 73 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.2380 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0960\n","100% 157/157 [00:07<00:00, 20.91it/s]\n","100% 40/40 [00:01<00:00, 21.52it/s]\n","Epoch: 74 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.2880 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0740\n","100% 157/157 [00:07<00:00, 20.76it/s]\n","100% 40/40 [00:01<00:00, 21.38it/s]\n","Epoch 00075: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch: 75 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3480 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1280\n","100% 157/157 [00:07<00:00, 20.87it/s]\n","100% 40/40 [00:02<00:00, 17.50it/s]\n","Epoch: 76 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3240 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0200\n","100% 157/157 [00:07<00:00, 21.16it/s]\n","100% 40/40 [00:01<00:00, 21.75it/s]\n","Epoch: 77 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3880 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0560\n","100% 157/157 [00:07<00:00, 20.77it/s]\n","100% 40/40 [00:01<00:00, 21.76it/s]\n","Epoch: 78 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4120 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1080\n","100% 157/157 [00:07<00:00, 20.59it/s]\n","100% 40/40 [00:01<00:00, 21.30it/s]\n","Epoch: 79 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4220 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0880\n","100% 157/157 [00:07<00:00, 20.86it/s]\n","100% 40/40 [00:01<00:00, 22.09it/s]\n","Epoch: 80 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3560 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0460\n","100% 157/157 [00:07<00:00, 20.76it/s]\n","100% 40/40 [00:01<00:00, 21.70it/s]\n","Epoch: 81 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5580 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0980\n","100% 157/157 [00:07<00:00, 20.99it/s]\n","100% 40/40 [00:01<00:00, 22.16it/s]\n","Epoch 00082: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch: 82 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4180 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0920\n","100% 157/157 [00:07<00:00, 20.71it/s]\n","100% 40/40 [00:01<00:00, 21.69it/s]\n","Epoch: 83 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4080 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0860\n","100% 157/157 [00:07<00:00, 21.03it/s]\n","100% 40/40 [00:01<00:00, 21.91it/s]\n","Epoch: 84 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5200 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0620\n","100% 157/157 [00:07<00:00, 20.86it/s]\n","100% 40/40 [00:01<00:00, 21.97it/s]\n","Epoch: 85 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3960 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0460\n","100% 157/157 [00:07<00:00, 20.87it/s]\n","100% 40/40 [00:01<00:00, 22.01it/s]\n","Epoch: 86 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5560 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0760\n","100% 157/157 [00:07<00:00, 20.81it/s]\n","100% 40/40 [00:01<00:00, 21.46it/s]\n","Epoch: 87 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4320 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0440\n","100% 157/157 [00:07<00:00, 20.70it/s]\n","100% 40/40 [00:01<00:00, 21.69it/s]\n","Epoch: 88 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5560 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0800\n","100% 157/157 [00:07<00:00, 20.82it/s]\n","100% 40/40 [00:01<00:00, 21.51it/s]\n","Epoch 00089: reducing learning rate of group 0 to 1.0000e-07.\n","Epoch: 89 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5080 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0980\n","100% 157/157 [00:07<00:00, 20.76it/s]\n","100% 40/40 [00:01<00:00, 21.97it/s]\n","Epoch: 90 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3220 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1400\n","100% 157/157 [00:07<00:00, 20.73it/s]\n","100% 40/40 [00:01<00:00, 21.44it/s]\n","Epoch: 91 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5820 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1260\n","100% 157/157 [00:07<00:00, 21.03it/s]\n","100% 40/40 [00:01<00:00, 22.10it/s]\n","Epoch: 92 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5760 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1740\n","100% 157/157 [00:07<00:00, 20.94it/s]\n","100% 40/40 [00:01<00:00, 21.23it/s]\n","Epoch: 93 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5460 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0860\n","100% 157/157 [00:07<00:00, 20.69it/s]\n","100% 40/40 [00:01<00:00, 22.13it/s]\n","Epoch: 94 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4500 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0720\n","100% 157/157 [00:07<00:00, 20.90it/s]\n","100% 40/40 [00:01<00:00, 21.63it/s]\n","Epoch: 95 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.5140 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0980\n","100% 157/157 [00:07<00:00, 20.86it/s]\n","100% 40/40 [00:01<00:00, 22.08it/s]\n","Epoch 00096: reducing learning rate of group 0 to 1.0000e-08.\n","Epoch: 96 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.3800 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.1060\n","100% 157/157 [00:07<00:00, 20.90it/s]\n","100% 40/40 [00:01<00:00, 21.82it/s]\n","Epoch: 97 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4220 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0160\n","100% 157/157 [00:07<00:00, 20.86it/s]\n","100% 40/40 [00:01<00:00, 22.00it/s]\n","Epoch: 98 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4760 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0920\n","100% 157/157 [00:07<00:00, 20.67it/s]\n","100% 40/40 [00:02<00:00, 17.15it/s]\n","Epoch: 99 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4840 \tValidation Loss: 0.0000 \tValidation Accuracy: 12.9880\n","100% 157/157 [00:07<00:00, 20.72it/s]\n","100% 40/40 [00:01<00:00, 21.87it/s]\n","Epoch: 100 \tTraining Loss: 0.0000 \tTraining Accuracy: 61.4620 \tValidation Loss: 0.0000 \tValidation Accuracy: 13.0680\n"]}]},{"cell_type":"code","source":["!python train_bayesian.py --net_type 3conv3fc --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmaMEbmoc_Ub","executionInfo":{"status":"ok","timestamp":1651072752141,"user_tz":240,"elapsed":3810,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"7b854c56-3895-4e32-bf6b-ef1463bf116b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"train_bayesian.py\", line 203, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"train_bayesian.py\", line 160, in run\n","    trainset, testset, inputs, outputs = data.getDataset(dataset)\n","TypeError: getDataset() missing 1 required positional argument: 'model'\n"]}]},{"cell_type":"code","source":["!python train_bayesian.py --net_type alexnet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JosOgCR_dC9R","executionInfo":{"status":"ok","timestamp":1651072756074,"user_tz":240,"elapsed":3947,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"dd3237fa-7cd9-45a6-a555-b5b017a448e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"train_bayesian.py\", line 203, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"train_bayesian.py\", line 160, in run\n","    trainset, testset, inputs, outputs = data.getDataset(dataset)\n","TypeError: getDataset() missing 1 required positional argument: 'model'\n"]}]},{"cell_type":"code","source":["!python main_bayesian.py --net_type alexnet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2QKDy6lkjEVu","executionInfo":{"status":"ok","timestamp":1651474713468,"user_tz":240,"elapsed":1353349,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"435a7baa-7934-4abc-c0bb-00a8a1b58a44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Epoch: 0 \tTraining Loss: 18058.4521 \tTraining Accuracy: 9.8602 \tValidation Loss: 13924.8890 \tValidation Accuracy: 9.4043 \ttrain_kl_div: 237029.6852\n","Validation loss decreased (inf --> 13924.888972).  Saving model ...\n","Epoch: 1 \tTraining Loss: 2260.7096 \tTraining Accuracy: 9.9448 \tValidation Loss: 12018.4889 \tValidation Accuracy: 9.9023 \ttrain_kl_div: 230127.5222\n","Validation loss decreased (13924.888972 --> 12018.488885).  Saving model ...\n","Epoch: 2 \tTraining Loss: 2036.2756 \tTraining Accuracy: 9.8651 \tValidation Loss: 11248.5086 \tValidation Accuracy: 9.9121 \ttrain_kl_div: 213921.2504\n","Validation loss decreased (12018.488885 --> 11248.508556).  Saving model ...\n","Epoch: 3 \tTraining Loss: 1938.2660 \tTraining Accuracy: 10.2981 \tValidation Loss: 10512.8003 \tValidation Accuracy: 10.5469 \ttrain_kl_div: 199192.6721\n","Validation loss decreased (11248.508556 --> 10512.800311).  Saving model ...\n","Epoch: 4 \tTraining Loss: 1844.9305 \tTraining Accuracy: 9.6537 \tValidation Loss: 9728.7892 \tValidation Accuracy: 9.6484 \ttrain_kl_div: 183594.4518\n","Validation loss decreased (10512.800311 --> 9728.789198).  Saving model ...\n","Epoch: 5 \tTraining Loss: 1745.0833 \tTraining Accuracy: 9.6014 \tValidation Loss: 8995.5889 \tValidation Accuracy: 9.6777 \ttrain_kl_div: 168859.2095\n","Validation loss decreased (9728.789198 --> 8995.588876).  Saving model ...\n","Epoch: 6 \tTraining Loss: 1651.1919 \tTraining Accuracy: 9.7109 \tValidation Loss: 8270.7064 \tValidation Accuracy: 9.9023 \ttrain_kl_div: 154266.4488\n","Validation loss decreased (8995.588876 --> 8270.706401).  Saving model ...\n","Epoch: 7 \tTraining Loss: 1557.2153 \tTraining Accuracy: 9.9522 \tValidation Loss: 7671.2507 \tValidation Accuracy: 10.1270 \ttrain_kl_div: 141926.6584\n","Validation loss decreased (8270.706401 --> 7671.250746).  Saving model ...\n","Epoch: 8 \tTraining Loss: 1478.2596 \tTraining Accuracy: 9.8726 \tValidation Loss: 7079.8868 \tValidation Accuracy: 10.4004 \ttrain_kl_div: 129742.9912\n","Validation loss decreased (7671.250746 --> 7079.886841).  Saving model ...\n","Epoch: 9 \tTraining Loss: 1398.5453 \tTraining Accuracy: 9.9149 \tValidation Loss: 6593.4044 \tValidation Accuracy: 10.5371 \ttrain_kl_div: 119593.3409\n","Validation loss decreased (7079.886841 --> 6593.404439).  Saving model ...\n","Epoch: 10 \tTraining Loss: 1335.7283 \tTraining Accuracy: 10.0070 \tValidation Loss: 5872.4440 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 105357.2269\n","Validation loss decreased (6593.404439 --> 5872.443954).  Saving model ...\n","Epoch: 11 \tTraining Loss: 1244.1729 \tTraining Accuracy: 10.0294 \tValidation Loss: 5374.1324 \tValidation Accuracy: 9.9609 \ttrain_kl_div: 95184.3416\n","Validation loss decreased (5872.443954 --> 5374.132385).  Saving model ...\n","Epoch: 12 \tTraining Loss: 1182.6743 \tTraining Accuracy: 9.9920 \tValidation Loss: 4709.5490 \tValidation Accuracy: 9.8926 \ttrain_kl_div: 82194.5573\n","Validation loss decreased (5374.132385 --> 4709.548979).  Saving model ...\n","Epoch: 13 \tTraining Loss: 1099.5790 \tTraining Accuracy: 9.8502 \tValidation Loss: 4296.0202 \tValidation Accuracy: 9.9316 \ttrain_kl_div: 73720.0731\n","Validation loss decreased (4709.548979 --> 4296.020161).  Saving model ...\n","Epoch: 14 \tTraining Loss: 1048.2336 \tTraining Accuracy: 9.8229 \tValidation Loss: 3866.1412 \tValidation Accuracy: 10.5176 \ttrain_kl_div: 65131.1631\n","Validation loss decreased (4296.020161 --> 3866.141214).  Saving model ...\n","Epoch: 15 \tTraining Loss: 992.0745 \tTraining Accuracy: 9.6586 \tValidation Loss: 3742.1486 \tValidation Accuracy: 9.6289 \ttrain_kl_div: 61919.9516\n","Validation loss decreased (3866.141214 --> 3742.148589).  Saving model ...\n","Epoch: 16 \tTraining Loss: 970.9543 \tTraining Accuracy: 9.8527 \tValidation Loss: 3375.4209 \tValidation Accuracy: 10.0293 \ttrain_kl_div: 54724.2960\n","Validation loss decreased (3742.148589 --> 3375.420929).  Saving model ...\n","Epoch: 17 \tTraining Loss: 927.7167 \tTraining Accuracy: 10.0717 \tValidation Loss: 2991.9179 \tValidation Accuracy: 10.0977 \ttrain_kl_div: 47303.2197\n","Validation loss decreased (3375.420929 --> 2991.917943).  Saving model ...\n","Epoch: 18 \tTraining Loss: 880.3508 \tTraining Accuracy: 10.1538 \tValidation Loss: 2761.1704 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 42522.6760\n","Validation loss decreased (2991.917943 --> 2761.170372).  Saving model ...\n","Epoch: 19 \tTraining Loss: 850.5866 \tTraining Accuracy: 9.9696 \tValidation Loss: 2688.6100 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 40766.7250\n","Validation loss decreased (2761.170372 --> 2688.610030).  Saving model ...\n","Epoch: 20 \tTraining Loss: 839.1471 \tTraining Accuracy: 10.0567 \tValidation Loss: 2528.0450 \tValidation Accuracy: 9.3945 \ttrain_kl_div: 37357.6720\n","Validation loss decreased (2688.610030 --> 2528.044995).  Saving model ...\n","Epoch: 21 \tTraining Loss: 816.2760 \tTraining Accuracy: 9.9099 \tValidation Loss: 2397.0308 \tValidation Accuracy: 9.8926 \ttrain_kl_div: 34723.5727\n","Validation loss decreased (2528.044995 --> 2397.030791).  Saving model ...\n","Epoch: 22 \tTraining Loss: 802.5180 \tTraining Accuracy: 10.2607 \tValidation Loss: 2096.6984 \tValidation Accuracy: 10.3027 \ttrain_kl_div: 29082.5870\n","Validation loss decreased (2397.030791 --> 2096.698384).  Saving model ...\n","Epoch: 23 \tTraining Loss: 765.5201 \tTraining Accuracy: 9.8353 \tValidation Loss: 2125.6707 \tValidation Accuracy: 10.5176 \ttrain_kl_div: 29269.2471\n","Epoch: 24 \tTraining Loss: 767.6011 \tTraining Accuracy: 9.9124 \tValidation Loss: 1943.7888 \tValidation Accuracy: 9.9609 \ttrain_kl_div: 25801.7853\n","Validation loss decreased (2096.698384 --> 1943.788797).  Saving model ...\n","Epoch: 25 \tTraining Loss: 745.8188 \tTraining Accuracy: 9.8428 \tValidation Loss: 1893.5024 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 24723.7362\n","Validation loss decreased (1943.788797 --> 1893.502415).  Saving model ...\n","Epoch: 26 \tTraining Loss: 739.2984 \tTraining Accuracy: 9.7208 \tValidation Loss: 1829.7958 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 23350.5805\n","Validation loss decreased (1893.502415 --> 1829.795833).  Saving model ...\n","Epoch: 27 \tTraining Loss: 729.8012 \tTraining Accuracy: 10.0020 \tValidation Loss: 1850.6230 \tValidation Accuracy: 10.4492 \ttrain_kl_div: 23563.4115\n","Epoch: 28 \tTraining Loss: 731.7533 \tTraining Accuracy: 9.9746 \tValidation Loss: 1787.2914 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 22315.1532\n","Validation loss decreased (1829.795833 --> 1787.291420).  Saving model ...\n","Epoch: 29 \tTraining Loss: 723.2403 \tTraining Accuracy: 10.2234 \tValidation Loss: 1746.1559 \tValidation Accuracy: 9.4922 \ttrain_kl_div: 21480.9866\n","Validation loss decreased (1787.291420 --> 1746.155865).  Saving model ...\n","Epoch: 30 \tTraining Loss: 718.8035 \tTraining Accuracy: 9.8826 \tValidation Loss: 1666.2703 \tValidation Accuracy: 9.8535 \ttrain_kl_div: 19916.2550\n","Validation loss decreased (1746.155865 --> 1666.270349).  Saving model ...\n","Epoch: 31 \tTraining Loss: 708.5948 \tTraining Accuracy: 9.9423 \tValidation Loss: 1654.2303 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 19659.1492\n","Validation loss decreased (1666.270349 --> 1654.230272).  Saving model ...\n","Epoch: 32 \tTraining Loss: 707.4325 \tTraining Accuracy: 9.9398 \tValidation Loss: 1590.2211 \tValidation Accuracy: 9.8242 \ttrain_kl_div: 18385.6502\n","Validation loss decreased (1654.230272 --> 1590.221146).  Saving model ...\n","Epoch: 33 \tTraining Loss: 698.7979 \tTraining Accuracy: 10.0269 \tValidation Loss: 1642.6957 \tValidation Accuracy: 9.3945 \ttrain_kl_div: 19287.3609\n","Epoch: 34 \tTraining Loss: 705.6655 \tTraining Accuracy: 9.8278 \tValidation Loss: 1554.1743 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 17598.8126\n","Validation loss decreased (1590.221146 --> 1554.174329).  Saving model ...\n","Epoch: 35 \tTraining Loss: 694.0844 \tTraining Accuracy: 9.8229 \tValidation Loss: 1600.8100 \tValidation Accuracy: 10.1953 \ttrain_kl_div: 18446.5976\n","Epoch: 36 \tTraining Loss: 700.4564 \tTraining Accuracy: 9.5641 \tValidation Loss: 1530.8874 \tValidation Accuracy: 9.9023 \ttrain_kl_div: 17134.8779\n","Validation loss decreased (1554.174329 --> 1530.887392).  Saving model ...\n","Epoch: 37 \tTraining Loss: 691.4425 \tTraining Accuracy: 9.9249 \tValidation Loss: 1626.9568 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 18723.7343\n","Epoch: 38 \tTraining Loss: 701.9665 \tTraining Accuracy: 9.9224 \tValidation Loss: 1633.8219 \tValidation Accuracy: 10.1758 \ttrain_kl_div: 18856.8321\n","Epoch: 39 \tTraining Loss: 701.0686 \tTraining Accuracy: 9.7930 \tValidation Loss: 1724.0621 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 20451.1208\n","Epoch: 40 \tTraining Loss: 711.2797 \tTraining Accuracy: 10.0468 \tValidation Loss: 1731.9216 \tValidation Accuracy: 10.0391 \ttrain_kl_div: 20493.2618\n","Epoch: 41 \tTraining Loss: 711.3093 \tTraining Accuracy: 10.0194 \tValidation Loss: 1839.5358 \tValidation Accuracy: 10.3027 \ttrain_kl_div: 22352.4471\n","Epoch: 42 \tTraining Loss: 722.8809 \tTraining Accuracy: 10.2632 \tValidation Loss: 1869.4998 \tValidation Accuracy: 9.3945 \ttrain_kl_div: 22870.0002\n","Epoch 00044: reducing learning rate of group 0 to 1.0000e-03.\n","Epoch: 43 \tTraining Loss: 724.2779 \tTraining Accuracy: 9.9149 \tValidation Loss: 2229.0149 \tValidation Accuracy: 9.8633 \ttrain_kl_div: 29304.9163\n","Epoch: 44 \tTraining Loss: 794.4067 \tTraining Accuracy: 10.0393 \tValidation Loss: 1670.6063 \tValidation Accuracy: 9.8047 \ttrain_kl_div: 22321.7189\n","Epoch: 45 \tTraining Loss: 725.2719 \tTraining Accuracy: 10.0095 \tValidation Loss: 1356.1437 \tValidation Accuracy: 9.6191 \ttrain_kl_div: 15725.1030\n","Validation loss decreased (1530.887392 --> 1356.143738).  Saving model ...\n","Epoch: 46 \tTraining Loss: 686.0319 \tTraining Accuracy: 9.7134 \tValidation Loss: 1158.6272 \tValidation Accuracy: 10.5859 \ttrain_kl_div: 11635.7992\n","Validation loss decreased (1356.143738 --> 1158.627156).  Saving model ...\n","Epoch: 47 \tTraining Loss: 661.5462 \tTraining Accuracy: 9.8378 \tValidation Loss: 1031.1149 \tValidation Accuracy: 9.3457 \ttrain_kl_div: 8994.4577\n","Validation loss decreased (1158.627156 --> 1031.114882).  Saving model ...\n","Epoch: 48 \tTraining Loss: 645.6824 \tTraining Accuracy: 10.1861 \tValidation Loss: 946.9257 \tValidation Accuracy: 10.1270 \ttrain_kl_div: 7249.7083\n","Validation loss decreased (1031.114882 --> 946.925742).  Saving model ...\n","Epoch: 49 \tTraining Loss: 635.0915 \tTraining Accuracy: 10.1911 \tValidation Loss: 890.7092 \tValidation Accuracy: 10.1660 \ttrain_kl_div: 6089.3238\n","Validation loss decreased (946.925742 --> 890.709163).  Saving model ...\n","Epoch: 50 \tTraining Loss: 628.2363 \tTraining Accuracy: 9.9821 \tValidation Loss: 852.8487 \tValidation Accuracy: 10.2441 \ttrain_kl_div: 5305.4276\n","Validation loss decreased (890.709163 --> 852.848679).  Saving model ...\n","Epoch: 51 \tTraining Loss: 623.5355 \tTraining Accuracy: 10.0518 \tValidation Loss: 827.2785 \tValidation Accuracy: 9.4434 \ttrain_kl_div: 4764.4535\n","Validation loss decreased (852.848679 --> 827.278484).  Saving model ...\n","Epoch: 52 \tTraining Loss: 620.2213 \tTraining Accuracy: 9.7557 \tValidation Loss: 808.3665 \tValidation Accuracy: 9.5312 \ttrain_kl_div: 4379.2982\n","Validation loss decreased (827.278484 --> 808.366481).  Saving model ...\n","Epoch: 53 \tTraining Loss: 617.9962 \tTraining Accuracy: 10.4474 \tValidation Loss: 794.7006 \tValidation Accuracy: 10.4004 \ttrain_kl_div: 4100.9934\n","Validation loss decreased (808.366481 --> 794.700571).  Saving model ...\n","Epoch: 54 \tTraining Loss: 616.3360 \tTraining Accuracy: 10.1065 \tValidation Loss: 784.6931 \tValidation Accuracy: 10.2148 \ttrain_kl_div: 3887.2127\n","Validation loss decreased (794.700571 --> 784.693111).  Saving model ...\n","Epoch: 55 \tTraining Loss: 614.7568 \tTraining Accuracy: 10.0318 \tValidation Loss: 775.4028 \tValidation Accuracy: 10.0000 \ttrain_kl_div: 3708.8820\n","Validation loss decreased (784.693111 --> 775.402820).  Saving model ...\n","Epoch: 56 \tTraining Loss: 613.3732 \tTraining Accuracy: 9.9821 \tValidation Loss: 768.0904 \tValidation Accuracy: 9.5117 \ttrain_kl_div: 3554.3703\n","Validation loss decreased (775.402820 --> 768.090401).  Saving model ...\n","Epoch: 57 \tTraining Loss: 613.2694 \tTraining Accuracy: 10.2657 \tValidation Loss: 763.0344 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 3433.3011\n","Validation loss decreased (768.090401 --> 763.034435).  Saving model ...\n","Epoch: 58 \tTraining Loss: 612.6020 \tTraining Accuracy: 9.7184 \tValidation Loss: 757.6194 \tValidation Accuracy: 10.7617 \ttrain_kl_div: 3322.7403\n","Validation loss decreased (763.034435 --> 757.619437).  Saving model ...\n","Epoch: 59 \tTraining Loss: 611.1179 \tTraining Accuracy: 9.7880 \tValidation Loss: 752.2657 \tValidation Accuracy: 9.6875 \ttrain_kl_div: 3213.3952\n","Validation loss decreased (757.619437 --> 752.265739).  Saving model ...\n","Epoch: 60 \tTraining Loss: 611.1778 \tTraining Accuracy: 9.7233 \tValidation Loss: 748.6078 \tValidation Accuracy: 9.9316 \ttrain_kl_div: 3119.1330\n","Validation loss decreased (752.265739 --> 748.607770).  Saving model ...\n","Epoch: 61 \tTraining Loss: 610.3961 \tTraining Accuracy: 9.9920 \tValidation Loss: 744.7568 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 3045.2459\n","Validation loss decreased (748.607770 --> 744.756837).  Saving model ...\n","Epoch: 62 \tTraining Loss: 609.9764 \tTraining Accuracy: 9.9473 \tValidation Loss: 739.7349 \tValidation Accuracy: 9.8145 \ttrain_kl_div: 2967.7392\n","Validation loss decreased (744.756837 --> 739.734921).  Saving model ...\n","Epoch: 63 \tTraining Loss: 609.4480 \tTraining Accuracy: 9.9423 \tValidation Loss: 736.8910 \tValidation Accuracy: 9.9805 \ttrain_kl_div: 2902.7980\n","Validation loss decreased (739.734921 --> 736.890971).  Saving model ...\n","Epoch: 64 \tTraining Loss: 609.0688 \tTraining Accuracy: 10.0518 \tValidation Loss: 734.5455 \tValidation Accuracy: 9.4141 \ttrain_kl_div: 2844.8721\n","Validation loss decreased (736.890971 --> 734.545499).  Saving model ...\n","Epoch: 65 \tTraining Loss: 609.1819 \tTraining Accuracy: 10.0741 \tValidation Loss: 733.1471 \tValidation Accuracy: 10.3027 \ttrain_kl_div: 2792.2482\n","Validation loss decreased (734.545499 --> 733.147148).  Saving model ...\n","Epoch: 66 \tTraining Loss: 608.8902 \tTraining Accuracy: 10.2881 \tValidation Loss: 731.8217 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 2778.2813\n","Validation loss decreased (733.147148 --> 731.821713).  Saving model ...\n","Epoch: 67 \tTraining Loss: 608.4904 \tTraining Accuracy: 10.0741 \tValidation Loss: 728.5314 \tValidation Accuracy: 10.4688 \ttrain_kl_div: 2717.8439\n","Validation loss decreased (731.821713 --> 728.531424).  Saving model ...\n","Epoch: 68 \tTraining Loss: 608.0303 \tTraining Accuracy: 9.8378 \tValidation Loss: 726.4105 \tValidation Accuracy: 9.5898 \ttrain_kl_div: 2665.9492\n","Validation loss decreased (728.531424 --> 726.410547).  Saving model ...\n","Epoch: 69 \tTraining Loss: 608.2716 \tTraining Accuracy: 9.9273 \tValidation Loss: 730.7927 \tValidation Accuracy: 10.3809 \ttrain_kl_div: 2687.0614\n","Epoch: 70 \tTraining Loss: 608.5622 \tTraining Accuracy: 9.9622 \tValidation Loss: 730.5264 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 2718.7100\n","Epoch: 71 \tTraining Loss: 608.3254 \tTraining Accuracy: 9.8577 \tValidation Loss: 738.0221 \tValidation Accuracy: 9.7266 \ttrain_kl_div: 2800.7605\n","Epoch: 72 \tTraining Loss: 609.4738 \tTraining Accuracy: 9.8751 \tValidation Loss: 750.3444 \tValidation Accuracy: 9.6191 \ttrain_kl_div: 3040.3444\n","Epoch: 73 \tTraining Loss: 610.4511 \tTraining Accuracy: 10.0169 \tValidation Loss: 775.4260 \tValidation Accuracy: 10.4785 \ttrain_kl_div: 3453.4043\n","Epoch: 74 \tTraining Loss: 612.9357 \tTraining Accuracy: 9.7333 \tValidation Loss: 805.3310 \tValidation Accuracy: 9.9414 \ttrain_kl_div: 3988.2718\n","Epoch 00076: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch: 75 \tTraining Loss: 616.0550 \tTraining Accuracy: 9.9721 \tValidation Loss: 842.1694 \tValidation Accuracy: 10.4102 \ttrain_kl_div: 4630.1797\n","Epoch: 76 \tTraining Loss: 622.0509 \tTraining Accuracy: 10.2060 \tValidation Loss: 791.6417 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 4091.9386\n","Epoch: 77 \tTraining Loss: 615.5871 \tTraining Accuracy: 10.0791 \tValidation Loss: 763.1091 \tValidation Accuracy: 10.1953 \ttrain_kl_div: 3491.3771\n","Epoch: 78 \tTraining Loss: 612.0464 \tTraining Accuracy: 10.1115 \tValidation Loss: 746.1116 \tValidation Accuracy: 9.5996 \ttrain_kl_div: 3122.2422\n","Epoch: 79 \tTraining Loss: 610.2119 \tTraining Accuracy: 10.0219 \tValidation Loss: 734.0328 \tValidation Accuracy: 9.8828 \ttrain_kl_div: 2884.9121\n","Epoch: 80 \tTraining Loss: 608.9845 \tTraining Accuracy: 10.1687 \tValidation Loss: 727.2592 \tValidation Accuracy: 10.0000 \ttrain_kl_div: 2732.6856\n","Epoch: 81 \tTraining Loss: 607.9935 \tTraining Accuracy: 9.8129 \tValidation Loss: 722.1207 \tValidation Accuracy: 9.1992 \ttrain_kl_div: 2628.3958\n","Validation loss decreased (726.410547 --> 722.120686).  Saving model ...\n","Epoch: 82 \tTraining Loss: 607.4312 \tTraining Accuracy: 10.1090 \tValidation Loss: 719.3680 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 2558.5687\n","Validation loss decreased (722.120686 --> 719.368002).  Saving model ...\n","Epoch: 83 \tTraining Loss: 606.7908 \tTraining Accuracy: 10.3006 \tValidation Loss: 716.7210 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 2501.4498\n","Validation loss decreased (719.368002 --> 716.720981).  Saving model ...\n","Epoch: 84 \tTraining Loss: 606.4762 \tTraining Accuracy: 10.2309 \tValidation Loss: 714.3870 \tValidation Accuracy: 9.7949 \ttrain_kl_div: 2470.4539\n","Validation loss decreased (716.720981 --> 714.387032).  Saving model ...\n","Epoch: 85 \tTraining Loss: 606.3247 \tTraining Accuracy: 10.1090 \tValidation Loss: 712.8358 \tValidation Accuracy: 9.7266 \ttrain_kl_div: 2438.7004\n","Validation loss decreased (714.387032 --> 712.835785).  Saving model ...\n","Epoch: 86 \tTraining Loss: 605.9421 \tTraining Accuracy: 9.7880 \tValidation Loss: 711.2767 \tValidation Accuracy: 10.1172 \ttrain_kl_div: 2414.3925\n","Validation loss decreased (712.835785 --> 711.276715).  Saving model ...\n","Epoch: 87 \tTraining Loss: 606.0753 \tTraining Accuracy: 9.8577 \tValidation Loss: 710.8595 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 2395.8011\n","Validation loss decreased (711.276715 --> 710.859479).  Saving model ...\n","Epoch: 88 \tTraining Loss: 605.8770 \tTraining Accuracy: 10.0368 \tValidation Loss: 710.1713 \tValidation Accuracy: 9.2578 \ttrain_kl_div: 2381.4181\n","Validation loss decreased (710.859479 --> 710.171266).  Saving model ...\n","Epoch: 89 \tTraining Loss: 605.7447 \tTraining Accuracy: 9.9970 \tValidation Loss: 709.4726 \tValidation Accuracy: 10.4102 \ttrain_kl_div: 2359.6432\n","Validation loss decreased (710.171266 --> 709.472580).  Saving model ...\n","Epoch: 90 \tTraining Loss: 605.6495 \tTraining Accuracy: 10.0940 \tValidation Loss: 708.8359 \tValidation Accuracy: 9.5508 \ttrain_kl_div: 2348.6293\n","Validation loss decreased (709.472580 --> 708.835881).  Saving model ...\n","Epoch: 91 \tTraining Loss: 605.6948 \tTraining Accuracy: 10.0269 \tValidation Loss: 708.9853 \tValidation Accuracy: 9.6777 \ttrain_kl_div: 2336.7857\n","Epoch: 92 \tTraining Loss: 605.6317 \tTraining Accuracy: 10.1164 \tValidation Loss: 708.6783 \tValidation Accuracy: 9.8730 \ttrain_kl_div: 2334.4216\n","Validation loss decreased (708.835881 --> 708.678304).  Saving model ...\n","Epoch: 93 \tTraining Loss: 605.5898 \tTraining Accuracy: 10.0493 \tValidation Loss: 707.8050 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 2316.9714\n","Validation loss decreased (708.678304 --> 707.805002).  Saving model ...\n","Epoch: 94 \tTraining Loss: 605.4091 \tTraining Accuracy: 10.0418 \tValidation Loss: 706.6901 \tValidation Accuracy: 10.4199 \ttrain_kl_div: 2301.2263\n","Validation loss decreased (707.805002 --> 706.690149).  Saving model ...\n","Epoch: 95 \tTraining Loss: 605.9074 \tTraining Accuracy: 9.9572 \tValidation Loss: 707.8728 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 2304.7545\n","Epoch: 96 \tTraining Loss: 605.6553 \tTraining Accuracy: 10.0468 \tValidation Loss: 707.7646 \tValidation Accuracy: 9.6484 \ttrain_kl_div: 2310.9160\n","Epoch: 97 \tTraining Loss: 605.3597 \tTraining Accuracy: 9.8676 \tValidation Loss: 706.1575 \tValidation Accuracy: 9.7363 \ttrain_kl_div: 2274.2904\n","Validation loss decreased (706.690149 --> 706.157503).  Saving model ...\n","Epoch: 98 \tTraining Loss: 605.3099 \tTraining Accuracy: 10.0368 \tValidation Loss: 705.9803 \tValidation Accuracy: 9.8438 \ttrain_kl_div: 2267.5231\n","Validation loss decreased (706.157503 --> 705.980286).  Saving model ...\n","Epoch: 99 \tTraining Loss: 605.6833 \tTraining Accuracy: 10.2583 \tValidation Loss: 707.2603 \tValidation Accuracy: 9.7754 \ttrain_kl_div: 2283.3022\n"]}]},{"cell_type":"code","source":["!python main_bayesian.py --net_type alexnet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCYsBTDxjG6M","executionInfo":{"status":"ok","timestamp":1651477687834,"user_tz":240,"elapsed":728977,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"a7664937-38b9-43a8-b62a-6f65b2ac41b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters initialized\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Epoch: 0 \tTraining Loss: 776.3799 \tTraining Accuracy: 9.9191 \tValidation Loss: 5577.7337 \tValidation Accuracy: 10.4925 \ttrain_kl_div: 186393.1649\n","Validation loss decreased (inf --> 5577.733730).  Saving model ...\n","Epoch: 1 \tTraining Loss: 770.0099 \tTraining Accuracy: 9.8068 \tValidation Loss: 35057.3936 \tValidation Accuracy: 9.7903 \ttrain_kl_div: 1295347.6917\n","Epoch: 2 \tTraining Loss: 3773.7852 \tTraining Accuracy: 10.0914 \tValidation Loss: 50690.0110 \tValidation Accuracy: 9.1673 \ttrain_kl_div: 1864897.8236\n","Epoch: 3 \tTraining Loss: 5701.4295 \tTraining Accuracy: 9.9666 \tValidation Loss: 24521.0780 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 935390.9853\n","Epoch: 4 \tTraining Loss: 3035.5751 \tTraining Accuracy: 9.8043 \tValidation Loss: 14580.3585 \tValidation Accuracy: 9.4244 \ttrain_kl_div: 557189.7100\n","Epoch: 5 \tTraining Loss: 1921.9565 \tTraining Accuracy: 10.0015 \tValidation Loss: 10684.7462 \tValidation Accuracy: 9.9486 \ttrain_kl_div: 402895.1502\n","Epoch: 6 \tTraining Loss: 1425.0317 \tTraining Accuracy: 9.8393 \tValidation Loss: 16804.7242 \tValidation Accuracy: 10.4331 \ttrain_kl_div: 622706.5531\n","Epoch 00008: reducing learning rate of group 0 to 1.0000e-03.\n","Epoch: 7 \tTraining Loss: 1957.2535 \tTraining Accuracy: 9.9166 \tValidation Loss: 35559.4514 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 1316653.5190\n","Epoch: 8 \tTraining Loss: 4620.7850 \tTraining Accuracy: 9.9091 \tValidation Loss: 22257.2749 \tValidation Accuracy: 9.6025 \ttrain_kl_div: 884160.1472\n","Epoch: 9 \tTraining Loss: 3011.5103 \tTraining Accuracy: 10.0839 \tValidation Loss: 15972.8242 \tValidation Accuracy: 9.9782 \ttrain_kl_div: 627380.4669\n","Epoch: 10 \tTraining Loss: 2241.2334 \tTraining Accuracy: 10.0614 \tValidation Loss: 12153.4400 \tValidation Accuracy: 9.8398 \ttrain_kl_div: 473377.8767\n","Epoch: 11 \tTraining Loss: 1769.6123 \tTraining Accuracy: 9.9366 \tValidation Loss: 9558.8500 \tValidation Accuracy: 9.7310 \ttrain_kl_div: 369301.2442\n","Epoch: 12 \tTraining Loss: 1448.5604 \tTraining Accuracy: 9.8817 \tValidation Loss: 7678.0070 \tValidation Accuracy: 10.0079 \ttrain_kl_div: 294068.6528\n","Epoch: 13 \tTraining Loss: 1215.1636 \tTraining Accuracy: 10.0414 \tValidation Loss: 6259.5858 \tValidation Accuracy: 9.8101 \ttrain_kl_div: 237420.1371\n","Epoch: 14 \tTraining Loss: 1039.0699 \tTraining Accuracy: 10.0864 \tValidation Loss: 5165.6651 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 193788.7771\n","Validation loss decreased (5577.733730 --> 5165.665104).  Saving model ...\n","Epoch: 15 \tTraining Loss: 903.1162 \tTraining Accuracy: 10.3884 \tValidation Loss: 4318.4968 \tValidation Accuracy: 9.9782 \ttrain_kl_div: 160003.2222\n","Validation loss decreased (5165.665104 --> 4318.496845).  Saving model ...\n","Epoch: 16 \tTraining Loss: 797.9158 \tTraining Accuracy: 9.7469 \tValidation Loss: 3664.7197 \tValidation Accuracy: 10.0672 \ttrain_kl_div: 133896.1402\n","Validation loss decreased (4318.496845 --> 3664.719733).  Saving model ...\n","Epoch: 17 \tTraining Loss: 716.1104 \tTraining Accuracy: 10.1388 \tValidation Loss: 3154.7053 \tValidation Accuracy: 9.6519 \ttrain_kl_div: 113605.7428\n","Validation loss decreased (3664.719733 --> 3154.705280).  Saving model ...\n","Epoch: 18 \tTraining Loss: 652.8023 \tTraining Accuracy: 10.3135 \tValidation Loss: 2754.4099 \tValidation Accuracy: 10.2354 \ttrain_kl_div: 97594.3213\n","Validation loss decreased (3154.705280 --> 2754.409885).  Saving model ...\n","Epoch: 19 \tTraining Loss: 603.0702 \tTraining Accuracy: 10.0314 \tValidation Loss: 2429.1207 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 84621.8932\n","Validation loss decreased (2754.409885 --> 2429.120653).  Saving model ...\n","Epoch: 20 \tTraining Loss: 562.2269 \tTraining Accuracy: 9.8567 \tValidation Loss: 2162.0031 \tValidation Accuracy: 9.8299 \ttrain_kl_div: 73951.3071\n","Validation loss decreased (2429.120653 --> 2162.003076).  Saving model ...\n","Epoch: 21 \tTraining Loss: 528.3727 \tTraining Accuracy: 9.9341 \tValidation Loss: 1945.3463 \tValidation Accuracy: 9.6420 \ttrain_kl_div: 65164.3425\n","Validation loss decreased (2162.003076 --> 1945.346284).  Saving model ...\n","Epoch: 22 \tTraining Loss: 500.1217 \tTraining Accuracy: 9.9715 \tValidation Loss: 1775.5376 \tValidation Accuracy: 9.8794 \ttrain_kl_div: 58351.0773\n","Validation loss decreased (1945.346284 --> 1775.537646).  Saving model ...\n","Epoch: 23 \tTraining Loss: 477.7470 \tTraining Accuracy: 9.8992 \tValidation Loss: 1651.2699 \tValidation Accuracy: 10.0475 \ttrain_kl_div: 53259.1599\n","Validation loss decreased (1775.537646 --> 1651.269902).  Saving model ...\n","Epoch: 24 \tTraining Loss: 461.4860 \tTraining Accuracy: 10.0589 \tValidation Loss: 1542.3515 \tValidation Accuracy: 9.9288 \ttrain_kl_div: 48575.8929\n","Validation loss decreased (1651.269902 --> 1542.351520).  Saving model ...\n","Epoch: 25 \tTraining Loss: 445.8833 \tTraining Accuracy: 9.7794 \tValidation Loss: 1405.2676 \tValidation Accuracy: 9.9980 \ttrain_kl_div: 43313.3230\n","Validation loss decreased (1542.351520 --> 1405.267560).  Saving model ...\n","Epoch: 26 \tTraining Loss: 428.5595 \tTraining Accuracy: 9.7444 \tValidation Loss: 1310.3686 \tValidation Accuracy: 9.8002 \ttrain_kl_div: 39186.2178\n","Validation loss decreased (1405.267560 --> 1310.368646).  Saving model ...\n","Epoch: 27 \tTraining Loss: 416.1696 \tTraining Accuracy: 9.8842 \tValidation Loss: 1248.4711 \tValidation Accuracy: 10.5320 \ttrain_kl_div: 36674.7448\n","Validation loss decreased (1310.368646 --> 1248.471107).  Saving model ...\n","Epoch: 28 \tTraining Loss: 407.2133 \tTraining Accuracy: 9.8692 \tValidation Loss: 1187.7760 \tValidation Accuracy: 9.6321 \ttrain_kl_div: 34240.1544\n","Validation loss decreased (1248.471107 --> 1187.776014).  Saving model ...\n","Epoch: 29 \tTraining Loss: 399.0479 \tTraining Accuracy: 10.1338 \tValidation Loss: 1166.5920 \tValidation Accuracy: 9.8398 \ttrain_kl_div: 33223.0013\n","Validation loss decreased (1187.776014 --> 1166.592006).  Saving model ...\n","Epoch: 30 \tTraining Loss: 394.3528 \tTraining Accuracy: 10.0364 \tValidation Loss: 1146.0099 \tValidation Accuracy: 9.9486 \ttrain_kl_div: 32416.6054\n","Validation loss decreased (1166.592006 --> 1146.009888).  Saving model ...\n","Epoch: 31 \tTraining Loss: 391.2132 \tTraining Accuracy: 10.1013 \tValidation Loss: 1165.0828 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 32633.6680\n","Epoch: 32 \tTraining Loss: 392.2628 \tTraining Accuracy: 9.8792 \tValidation Loss: 1079.7781 \tValidation Accuracy: 9.7706 \ttrain_kl_div: 29508.1695\n","Validation loss decreased (1146.009888 --> 1079.778129).  Saving model ...\n","Epoch: 33 \tTraining Loss: 381.9633 \tTraining Accuracy: 10.0190 \tValidation Loss: 982.4846 \tValidation Accuracy: 9.7013 \ttrain_kl_div: 25943.7327\n","Validation loss decreased (1079.778129 --> 982.484640).  Saving model ...\n","Epoch: 34 \tTraining Loss: 371.1645 \tTraining Accuracy: 9.8143 \tValidation Loss: 936.1911 \tValidation Accuracy: 9.6717 \ttrain_kl_div: 24106.9518\n","Validation loss decreased (982.484640 --> 936.191114).  Saving model ...\n","Epoch: 35 \tTraining Loss: 366.3343 \tTraining Accuracy: 9.8243 \tValidation Loss: 926.9874 \tValidation Accuracy: 9.6618 \ttrain_kl_div: 23692.5493\n","Validation loss decreased (936.191114 --> 926.987353).  Saving model ...\n","Epoch: 36 \tTraining Loss: 364.8243 \tTraining Accuracy: 10.0339 \tValidation Loss: 943.9314 \tValidation Accuracy: 10.4035 \ttrain_kl_div: 24150.9209\n","Epoch: 37 \tTraining Loss: 366.0988 \tTraining Accuracy: 9.7494 \tValidation Loss: 929.4333 \tValidation Accuracy: 9.8497 \ttrain_kl_div: 23565.7841\n","Epoch: 38 \tTraining Loss: 363.9215 \tTraining Accuracy: 9.8967 \tValidation Loss: 897.6358 \tValidation Accuracy: 9.6025 \ttrain_kl_div: 22365.1628\n","Validation loss decreased (926.987353 --> 897.635845).  Saving model ...\n","Epoch: 39 \tTraining Loss: 360.4746 \tTraining Accuracy: 9.9790 \tValidation Loss: 897.1454 \tValidation Accuracy: 9.3849 \ttrain_kl_div: 22323.1660\n","Validation loss decreased (897.635845 --> 897.145353).  Saving model ...\n","Epoch: 40 \tTraining Loss: 359.9855 \tTraining Accuracy: 9.9541 \tValidation Loss: 888.0628 \tValidation Accuracy: 9.7013 \ttrain_kl_div: 22126.3081\n","Validation loss decreased (897.145353 --> 888.062832).  Saving model ...\n","Epoch: 41 \tTraining Loss: 359.3923 \tTraining Accuracy: 10.1213 \tValidation Loss: 887.7948 \tValidation Accuracy: 9.8299 \ttrain_kl_div: 22055.4117\n","Validation loss decreased (888.062832 --> 887.794847).  Saving model ...\n","Epoch: 42 \tTraining Loss: 359.5022 \tTraining Accuracy: 9.8642 \tValidation Loss: 877.0194 \tValidation Accuracy: 9.8299 \ttrain_kl_div: 21655.2510\n","Validation loss decreased (887.794847 --> 877.019401).  Saving model ...\n","Epoch: 43 \tTraining Loss: 357.7675 \tTraining Accuracy: 10.0689 \tValidation Loss: 840.9196 \tValidation Accuracy: 9.8497 \ttrain_kl_div: 20303.2915\n","Validation loss decreased (877.019401 --> 840.919599).  Saving model ...\n","Traceback (most recent call last):\n","  File \"main_bayesian.py\", line 152, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"main_bayesian.py\", line 127, in run\n","    train_loss, train_acc, train_kl = train_model(net, optimizer, criterion, train_loader,beta_type,num_ens=train_ens)\n","  File \"main_bayesian.py\", line 58, in train_model\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n","    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["!python main_bayesian.py --net_type alexnet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIxt4HY_jHlu","executionInfo":{"status":"ok","timestamp":1651483323048,"user_tz":240,"elapsed":1532664,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"4825358b-caf4-4324-ac6f-0243918974a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["New Parameters initialized\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Epoch: 0 \tTraining Loss: 11699854.8997 \tTraining Accuracy: 9.8726 \tValidation Loss: 70241722.9919 \tValidation Accuracy: 10.4492 \ttrain_kl_div: 1434324908.8408\n","Validation loss decreased (inf --> 70241722.991879).  Saving model ...\n","Epoch: 1 \tTraining Loss: 8734460.9367 \tTraining Accuracy: 10.8330 \tValidation Loss: 46542189.0844 \tValidation Accuracy: 11.1816 \ttrain_kl_div: 961840185.0701\n","Validation loss decreased (70241722.991879 --> 46542189.084381).  Saving model ...\n","Epoch: 2 \tTraining Loss: 5799165.1996 \tTraining Accuracy: 11.4948 \tValidation Loss: 31905489.7682 \tValidation Accuracy: 11.8652 \ttrain_kl_div: 657236784.1019\n","Validation loss decreased (46542189.084381 --> 31905489.768152).  Saving model ...\n","Epoch: 3 \tTraining Loss: 3986259.2124 \tTraining Accuracy: 11.9750 \tValidation Loss: 22896134.2855 \tValidation Accuracy: 12.1680 \ttrain_kl_div: 469785707.8217\n","Validation loss decreased (31905489.768152 --> 22896134.285530).  Saving model ...\n","Epoch: 4 \tTraining Loss: 2866880.5753 \tTraining Accuracy: 11.8456 \tValidation Loss: 17039943.2272 \tValidation Accuracy: 12.3145 \ttrain_kl_div: 348561921.4268\n","Validation loss decreased (22896134.285530 --> 17039943.227248).  Saving model ...\n","Epoch: 5 \tTraining Loss: 2137195.1938 \tTraining Accuracy: 11.9029 \tValidation Loss: 13035778.5711 \tValidation Accuracy: 11.9824 \ttrain_kl_div: 266050792.8662\n","Validation loss decreased (17039943.227248 --> 13035778.571077).  Saving model ...\n","Epoch: 6 \tTraining Loss: 1637112.3931 \tTraining Accuracy: 11.7113 \tValidation Loss: 10182769.7291 \tValidation Accuracy: 11.5723 \ttrain_kl_div: 207470901.7070\n","Validation loss decreased (13035778.571077 --> 10182769.729132).  Saving model ...\n","Epoch: 7 \tTraining Loss: 1280130.2219 \tTraining Accuracy: 11.8581 \tValidation Loss: 8081668.0546 \tValidation Accuracy: 11.8555 \ttrain_kl_div: 164450494.2675\n","Validation loss decreased (10182769.729132 --> 8081668.054575).  Saving model ...\n","Epoch: 8 \tTraining Loss: 1016831.0202 \tTraining Accuracy: 11.7262 \tValidation Loss: 6492511.5207 \tValidation Accuracy: 12.0703 \ttrain_kl_div: 131984296.8153\n","Validation loss decreased (8081668.054575 --> 6492511.520743).  Saving model ...\n","Epoch: 9 \tTraining Loss: 817438.3526 \tTraining Accuracy: 11.7436 \tValidation Loss: 5264196.3732 \tValidation Accuracy: 11.6406 \ttrain_kl_div: 106934682.7006\n","Validation loss decreased (6492511.520743 --> 5264196.373221).  Saving model ...\n","Epoch: 10 \tTraining Loss: 663164.8132 \tTraining Accuracy: 11.7312 \tValidation Loss: 4297754.0225 \tValidation Accuracy: 11.3965 \ttrain_kl_div: 87253777.4268\n","Validation loss decreased (5264196.373221 --> 4297754.022513).  Saving model ...\n","Epoch: 11 \tTraining Loss: 541678.7988 \tTraining Accuracy: 11.5794 \tValidation Loss: 3526119.4956 \tValidation Accuracy: 12.0117 \ttrain_kl_div: 71558485.5032\n","Validation loss decreased (4297754.022513 --> 3526119.495567).  Saving model ...\n","Epoch: 12 \tTraining Loss: 444613.5804 \tTraining Accuracy: 11.4799 \tValidation Loss: 2902541.5923 \tValidation Accuracy: 12.1387 \ttrain_kl_div: 58886941.4013\n","Validation loss decreased (3526119.495567 --> 2902541.592346).  Saving model ...\n","Epoch: 13 \tTraining Loss: 366124.7134 \tTraining Accuracy: 11.7188 \tValidation Loss: 2393614.4899 \tValidation Accuracy: 11.8652 \ttrain_kl_div: 48553072.9172\n","Validation loss decreased (2902541.592346 --> 2393614.489909).  Saving model ...\n","Epoch: 14 \tTraining Loss: 302037.4316 \tTraining Accuracy: 11.6765 \tValidation Loss: 1974922.0966 \tValidation Accuracy: 12.0801 \ttrain_kl_div: 40056804.7389\n","Validation loss decreased (2393614.489909 --> 1974922.096555).  Saving model ...\n","Epoch: 15 \tTraining Loss: 249294.4592 \tTraining Accuracy: 11.5794 \tValidation Loss: 1628304.3184 \tValidation Accuracy: 12.3535 \ttrain_kl_div: 33026416.3185\n","Validation loss decreased (1974922.096555 --> 1628304.318440).  Saving model ...\n","Epoch: 16 \tTraining Loss: 205613.0402 \tTraining Accuracy: 11.7212 \tValidation Loss: 1339994.9445 \tValidation Accuracy: 11.1621 \ttrain_kl_div: 27180816.9682\n","Validation loss decreased (1628304.318440 --> 1339994.944484).  Saving model ...\n","Epoch: 17 \tTraining Loss: 169281.2701 \tTraining Accuracy: 11.5421 \tValidation Loss: 1099421.9304 \tValidation Accuracy: 11.8652 \ttrain_kl_div: 22304223.0573\n","Validation loss decreased (1339994.944484 --> 1099421.930380).  Saving model ...\n","Epoch: 18 \tTraining Loss: 138957.9821 \tTraining Accuracy: 11.5869 \tValidation Loss: 898330.6153 \tValidation Accuracy: 11.5820 \ttrain_kl_div: 18228484.5732\n","Validation loss decreased (1099421.930380 --> 898330.615338).  Saving model ...\n","Epoch: 19 \tTraining Loss: 113604.9449 \tTraining Accuracy: 11.7685 \tValidation Loss: 730180.2469 \tValidation Accuracy: 11.9043 \ttrain_kl_div: 14820649.0892\n","Validation loss decreased (898330.615338 --> 730180.246921).  Saving model ...\n","Epoch: 20 \tTraining Loss: 92407.5542 \tTraining Accuracy: 11.7287 \tValidation Loss: 589762.1221 \tValidation Accuracy: 12.0117 \ttrain_kl_div: 11974413.6943\n","Validation loss decreased (730180.246921 --> 589762.122122).  Saving model ...\n","Epoch: 21 \tTraining Loss: 74715.7831 \tTraining Accuracy: 11.5545 \tValidation Loss: 472843.1526 \tValidation Accuracy: 11.4160 \ttrain_kl_div: 9603576.6752\n","Validation loss decreased (589762.122122 --> 472843.152570).  Saving model ...\n","Epoch: 22 \tTraining Loss: 59979.6937 \tTraining Accuracy: 11.4675 \tValidation Loss: 375877.7795 \tValidation Accuracy: 11.9824 \ttrain_kl_div: 7637262.8248\n","Validation loss decreased (472843.152570 --> 375877.779541).  Saving model ...\n","Epoch: 23 \tTraining Loss: 47763.1304 \tTraining Accuracy: 11.8929 \tValidation Loss: 295987.6430 \tValidation Accuracy: 12.1680 \ttrain_kl_div: 6016116.7962\n","Validation loss decreased (375877.779541 --> 295987.642992).  Saving model ...\n","Epoch: 24 \tTraining Loss: 37705.0300 \tTraining Accuracy: 11.9078 \tValidation Loss: 230682.5126 \tValidation Accuracy: 12.1387 \ttrain_kl_div: 4690068.5255\n","Validation loss decreased (295987.642992 --> 230682.512582).  Saving model ...\n","Epoch: 25 \tTraining Loss: 29483.5404 \tTraining Accuracy: 11.8805 \tValidation Loss: 177823.3027 \tValidation Accuracy: 12.0215 \ttrain_kl_div: 3615982.0892\n","Validation loss decreased (230682.512582 --> 177823.302731).  Saving model ...\n","Epoch: 26 \tTraining Loss: 22836.3904 \tTraining Accuracy: 11.4973 \tValidation Loss: 135564.7607 \tValidation Accuracy: 11.4551 \ttrain_kl_div: 2756302.1131\n","Validation loss decreased (177823.302731 --> 135564.760748).  Saving model ...\n","Epoch: 27 \tTraining Loss: 17525.5636 \tTraining Accuracy: 11.3431 \tValidation Loss: 102258.5517 \tValidation Accuracy: 12.3730 \ttrain_kl_div: 2077898.9443\n","Validation loss decreased (135564.760748 --> 102258.551697).  Saving model ...\n","Epoch: 28 \tTraining Loss: 13340.9368 \tTraining Accuracy: 11.4948 \tValidation Loss: 76434.5359 \tValidation Accuracy: 12.0020 \ttrain_kl_div: 1551293.8272\n","Validation loss decreased (102258.551697 --> 76434.535893).  Saving model ...\n","Epoch: 29 \tTraining Loss: 10102.4029 \tTraining Accuracy: 11.4301 \tValidation Loss: 56796.4832 \tValidation Accuracy: 11.4844 \ttrain_kl_div: 1150153.4092\n","Validation loss decreased (76434.535893 --> 56796.483235).  Saving model ...\n","Epoch: 30 \tTraining Loss: 7638.1218 \tTraining Accuracy: 11.8581 \tValidation Loss: 42181.8650 \tValidation Accuracy: 11.8750 \ttrain_kl_div: 851061.6198\n","Validation loss decreased (56796.483235 --> 42181.864973).  Saving model ...\n","Epoch: 31 \tTraining Loss: 5809.7296 \tTraining Accuracy: 11.5943 \tValidation Loss: 31561.2355 \tValidation Accuracy: 11.2891 \ttrain_kl_div: 633277.9554\n","Validation loss decreased (42181.864973 --> 31561.235481).  Saving model ...\n","Epoch: 32 \tTraining Loss: 4480.3892 \tTraining Accuracy: 11.4177 \tValidation Loss: 24046.0565 \tValidation Accuracy: 11.7285 \ttrain_kl_div: 478855.2347\n","Validation loss decreased (31561.235481 --> 24046.056526).  Saving model ...\n","Epoch: 33 \tTraining Loss: 3542.3042 \tTraining Accuracy: 11.5421 \tValidation Loss: 18883.4335 \tValidation Accuracy: 12.1973 \ttrain_kl_div: 372422.1975\n","Validation loss decreased (24046.056526 --> 18883.433546).  Saving model ...\n","Epoch: 34 \tTraining Loss: 2898.5716 \tTraining Accuracy: 11.8730 \tValidation Loss: 15438.9447 \tValidation Accuracy: 12.4414 \ttrain_kl_div: 301297.2994\n","Validation loss decreased (18883.433546 --> 15438.944719).  Saving model ...\n","Epoch: 35 \tTraining Loss: 2468.3973 \tTraining Accuracy: 11.7909 \tValidation Loss: 13259.9061 \tValidation Accuracy: 12.2754 \ttrain_kl_div: 255472.4386\n","Validation loss decreased (15438.944719 --> 13259.906125).  Saving model ...\n","Epoch: 36 \tTraining Loss: 321666.1054 \tTraining Accuracy: 9.8627 \tValidation Loss: 123207.3708 \tValidation Accuracy: 10.4297 \ttrain_kl_div: 402399.0804\n","Epoch: 37 \tTraining Loss: 13186.8474 \tTraining Accuracy: 10.0692 \tValidation Loss: 96208.5400 \tValidation Accuracy: 9.8047 \ttrain_kl_div: 1857838.8766\n","Epoch: 38 \tTraining Loss: 1219379.0564 \tTraining Accuracy: 10.0219 \tValidation Loss: 159510.4130 \tValidation Accuracy: 9.8535 \ttrain_kl_div: 2414426.6592\n","Epoch: 39 \tTraining Loss: 21138.6372 \tTraining Accuracy: 9.9074 \tValidation Loss: 157909.3638 \tValidation Accuracy: 9.7070 \ttrain_kl_div: 2999762.1083\n","Epoch: 40 \tTraining Loss: 19781.7235 \tTraining Accuracy: 9.9920 \tValidation Loss: 142289.5084 \tValidation Accuracy: 10.0586 \ttrain_kl_div: 2833422.9283\n","Epoch: 41 \tTraining Loss: 18572.0566 \tTraining Accuracy: 9.7830 \tValidation Loss: 145093.7232 \tValidation Accuracy: 10.1172 \ttrain_kl_div: 2676942.1162\n","Epoch 00043: reducing learning rate of group 0 to 1.0000e-03.\n","Epoch: 42 \tTraining Loss: 7572576.5483 \tTraining Accuracy: 9.8104 \tValidation Loss: 226845.5634 \tValidation Accuracy: 9.9414 \ttrain_kl_div: 3481323.4682\n","Epoch: 43 \tTraining Loss: 29483.0640 \tTraining Accuracy: 10.0791 \tValidation Loss: 226211.2690 \tValidation Accuracy: 9.6973 \ttrain_kl_div: 4513341.2420\n","Epoch: 44 \tTraining Loss: 29323.9906 \tTraining Accuracy: 9.8627 \tValidation Loss: 225234.4656 \tValidation Accuracy: 10.1855 \ttrain_kl_div: 4494251.0350\n","Epoch: 45 \tTraining Loss: 29199.3784 \tTraining Accuracy: 10.0891 \tValidation Loss: 224216.9969 \tValidation Accuracy: 10.0488 \ttrain_kl_div: 4473961.2420\n","Epoch: 46 \tTraining Loss: 288709.3276 \tTraining Accuracy: 10.0269 \tValidation Loss: 223062.4158 \tValidation Accuracy: 9.4629 \ttrain_kl_div: 4452054.3662\n","Epoch: 47 \tTraining Loss: 28922.0465 \tTraining Accuracy: 10.0518 \tValidation Loss: 221981.2147 \tValidation Accuracy: 9.4629 \ttrain_kl_div: 4429326.6592\n","Epoch: 48 \tTraining Loss: 28783.8796 \tTraining Accuracy: 10.1911 \tValidation Loss: 220861.4809 \tValidation Accuracy: 9.4727 \ttrain_kl_div: 4406989.6338\n","Epoch 00050: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch: 49 \tTraining Loss: 28641.1260 \tTraining Accuracy: 9.9074 \tValidation Loss: 219703.9235 \tValidation Accuracy: 9.9805 \ttrain_kl_div: 4383890.5032\n","Epoch: 50 \tTraining Loss: 28503.9459 \tTraining Accuracy: 9.8627 \tValidation Loss: 219582.8676 \tValidation Accuracy: 10.4688 \ttrain_kl_div: 4380030.0350\n","Epoch: 51 \tTraining Loss: 28486.3286 \tTraining Accuracy: 9.8428 \tValidation Loss: 219453.9394 \tValidation Accuracy: 9.9316 \ttrain_kl_div: 4377458.5000\n","Epoch: 52 \tTraining Loss: 28469.6754 \tTraining Accuracy: 9.8900 \tValidation Loss: 219315.7552 \tValidation Accuracy: 9.9219 \ttrain_kl_div: 4374704.9936\n","Epoch: 53 \tTraining Loss: 28451.9636 \tTraining Accuracy: 10.1140 \tValidation Loss: 219167.6659 \tValidation Accuracy: 10.1270 \ttrain_kl_div: 4371757.5573\n","Epoch: 54 \tTraining Loss: 28433.1182 \tTraining Accuracy: 9.9423 \tValidation Loss: 219009.3757 \tValidation Accuracy: 9.9414 \ttrain_kl_div: 4368605.7675\n","Epoch: 55 \tTraining Loss: 28412.7716 \tTraining Accuracy: 9.7606 \tValidation Loss: 218840.6293 \tValidation Accuracy: 9.9414 \ttrain_kl_div: 4365239.7484\n","Epoch 00057: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch: 56 \tTraining Loss: 28391.2106 \tTraining Accuracy: 9.9398 \tValidation Loss: 218659.7753 \tValidation Accuracy: 10.2344 \ttrain_kl_div: 4361648.1688\n","Epoch: 57 \tTraining Loss: 41447.5401 \tTraining Accuracy: 10.0368 \tValidation Loss: 218640.6984 \tValidation Accuracy: 10.5371 \ttrain_kl_div: 4361043.1369\n","Epoch: 58 \tTraining Loss: 28367.1312 \tTraining Accuracy: 9.7781 \tValidation Loss: 218620.3790 \tValidation Accuracy: 9.7656 \ttrain_kl_div: 4360635.6274\n","Epoch: 59 \tTraining Loss: 28364.3718 \tTraining Accuracy: 10.1438 \tValidation Loss: 218598.8897 \tValidation Accuracy: 9.8535 \ttrain_kl_div: 4360205.7134\n","Epoch: 60 \tTraining Loss: 28361.4906 \tTraining Accuracy: 10.2682 \tValidation Loss: 218575.8857 \tValidation Accuracy: 9.8926 \ttrain_kl_div: 4359745.7834\n","Epoch: 61 \tTraining Loss: 28358.7407 \tTraining Accuracy: 10.0468 \tValidation Loss: 218551.0674 \tValidation Accuracy: 10.0098 \ttrain_kl_div: 4359253.7675\n","Epoch: 62 \tTraining Loss: 73883.3373 \tTraining Accuracy: 10.6787 \tValidation Loss: 218524.0061 \tValidation Accuracy: 9.8438 \ttrain_kl_div: 4358722.9236\n","Epoch 00064: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch: 63 \tTraining Loss: 28352.0883 \tTraining Accuracy: 9.9448 \tValidation Loss: 218495.6341 \tValidation Accuracy: 10.5566 \ttrain_kl_div: 4358153.9554\n","Epoch: 64 \tTraining Loss: 28348.6689 \tTraining Accuracy: 10.2234 \tValidation Loss: 218492.8321 \tValidation Accuracy: 10.1270 \ttrain_kl_div: 4358064.8344\n","Epoch: 65 \tTraining Loss: 28348.1819 \tTraining Accuracy: 10.0617 \tValidation Loss: 218490.0183 \tValidation Accuracy: 10.2148 \ttrain_kl_div: 4358006.1815\n","Epoch: 66 \tTraining Loss: 43622.7372 \tTraining Accuracy: 10.2881 \tValidation Loss: 218487.1789 \tValidation Accuracy: 9.9219 \ttrain_kl_div: 4357944.1178\n","Epoch: 67 \tTraining Loss: 161157.0029 \tTraining Accuracy: 10.0095 \tValidation Loss: 218483.1347 \tValidation Accuracy: 10.5469 \ttrain_kl_div: 4357875.2675\n","Epoch: 68 \tTraining Loss: 28347.1956 \tTraining Accuracy: 9.8651 \tValidation Loss: 218480.1078 \tValidation Accuracy: 9.8535 \ttrain_kl_div: 4357805.8567\n","Epoch: 69 \tTraining Loss: 28346.7657 \tTraining Accuracy: 9.9597 \tValidation Loss: 218476.2060 \tValidation Accuracy: 10.1074 \ttrain_kl_div: 4357731.7006\n","Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.\n","Epoch: 70 \tTraining Loss: 28346.2390 \tTraining Accuracy: 9.9970 \tValidation Loss: 218472.5574 \tValidation Accuracy: 10.1562 \ttrain_kl_div: 4357653.5096\n","Epoch: 71 \tTraining Loss: 28345.5932 \tTraining Accuracy: 10.1289 \tValidation Loss: 218472.2620 \tValidation Accuracy: 10.2637 \ttrain_kl_div: 4357643.7452\n","Epoch: 72 \tTraining Loss: 28345.5328 \tTraining Accuracy: 10.1587 \tValidation Loss: 218471.8658 \tValidation Accuracy: 10.3320 \ttrain_kl_div: 4357637.8535\n","Epoch: 73 \tTraining Loss: 28345.5348 \tTraining Accuracy: 10.0866 \tValidation Loss: 218471.7664 \tValidation Accuracy: 10.0293 \ttrain_kl_div: 4357632.3057\n","Epoch: 74 \tTraining Loss: 28345.5120 \tTraining Accuracy: 9.9597 \tValidation Loss: 218471.5521 \tValidation Accuracy: 9.7949 \ttrain_kl_div: 4357625.7834\n","Epoch: 75 \tTraining Loss: 28345.5607 \tTraining Accuracy: 10.2384 \tValidation Loss: 218470.8452 \tValidation Accuracy: 9.8730 \ttrain_kl_div: 4357618.8280\n","Epoch: 76 \tTraining Loss: 28345.4889 \tTraining Accuracy: 10.0443 \tValidation Loss: 218470.4744 \tValidation Accuracy: 9.4824 \ttrain_kl_div: 4357611.3949\n","Epoch 00078: reducing learning rate of group 0 to 1.0000e-08.\n","Epoch: 77 \tTraining Loss: 28345.4282 \tTraining Accuracy: 10.1438 \tValidation Loss: 218469.9935 \tValidation Accuracy: 10.2148 \ttrain_kl_div: 4357603.8471\n","Epoch: 78 \tTraining Loss: 28345.4626 \tTraining Accuracy: 10.1762 \tValidation Loss: 218470.6445 \tValidation Accuracy: 9.8535 \ttrain_kl_div: 4357603.0064\n","Epoch: 79 \tTraining Loss: 28345.5487 \tTraining Accuracy: 9.6487 \tValidation Loss: 218470.3482 \tValidation Accuracy: 9.5508 \ttrain_kl_div: 4357602.5127\n","Epoch: 80 \tTraining Loss: 28345.4768 \tTraining Accuracy: 9.9995 \tValidation Loss: 218470.3334 \tValidation Accuracy: 9.5215 \ttrain_kl_div: 4357602.5000\n","Epoch: 81 \tTraining Loss: 28345.4487 \tTraining Accuracy: 10.1189 \tValidation Loss: 218470.2626 \tValidation Accuracy: 9.4336 \ttrain_kl_div: 4357602.0287\n","Epoch: 82 \tTraining Loss: 28345.4447 \tTraining Accuracy: 9.7084 \tValidation Loss: 218470.3257 \tValidation Accuracy: 9.3555 \ttrain_kl_div: 4357602.0000\n","Epoch: 83 \tTraining Loss: 28345.4730 \tTraining Accuracy: 10.0617 \tValidation Loss: 218470.4996 \tValidation Accuracy: 9.2383 \ttrain_kl_div: 4357601.5127\n","Epoch: 84 \tTraining Loss: 28345.3572 \tTraining Accuracy: 10.0269 \tValidation Loss: 218470.3655 \tValidation Accuracy: 10.1465 \ttrain_kl_div: 4357601.5000\n","Epoch: 85 \tTraining Loss: 28345.4669 \tTraining Accuracy: 10.0518 \tValidation Loss: 218470.2688 \tValidation Accuracy: 10.0098 \ttrain_kl_div: 4357601.0223\n","Epoch: 86 \tTraining Loss: 38949.7954 \tTraining Accuracy: 9.6736 \tValidation Loss: 218469.7702 \tValidation Accuracy: 10.2246 \ttrain_kl_div: 4357600.5191\n","Epoch: 87 \tTraining Loss: 28345.4103 \tTraining Accuracy: 10.0219 \tValidation Loss: 218469.9324 \tValidation Accuracy: 9.8340 \ttrain_kl_div: 4357600.5000\n","Epoch: 88 \tTraining Loss: 28345.2928 \tTraining Accuracy: 10.1513 \tValidation Loss: 218470.0197 \tValidation Accuracy: 10.4395 \ttrain_kl_div: 4357600.0096\n","Epoch: 89 \tTraining Loss: 28345.3469 \tTraining Accuracy: 10.0916 \tValidation Loss: 218470.3884 \tValidation Accuracy: 9.7656 \ttrain_kl_div: 4357599.5255\n","Epoch: 90 \tTraining Loss: 98035.4331 \tTraining Accuracy: 9.8328 \tValidation Loss: 218486.4915 \tValidation Accuracy: 9.9121 \ttrain_kl_div: 4357599.5000\n","Epoch: 91 \tTraining Loss: 28345.3284 \tTraining Accuracy: 10.0667 \tValidation Loss: 218470.2855 \tValidation Accuracy: 9.4434 \ttrain_kl_div: 4357599.5000\n","Epoch: 92 \tTraining Loss: 28345.3212 \tTraining Accuracy: 10.0393 \tValidation Loss: 218469.9222 \tValidation Accuracy: 10.4102 \ttrain_kl_div: 4357598.5318\n","Epoch: 93 \tTraining Loss: 28345.4944 \tTraining Accuracy: 9.9771 \tValidation Loss: 218470.1523 \tValidation Accuracy: 9.9707 \ttrain_kl_div: 4357598.5000\n","Epoch: 94 \tTraining Loss: 28345.1788 \tTraining Accuracy: 10.2458 \tValidation Loss: 218520.3746 \tValidation Accuracy: 10.2051 \ttrain_kl_div: 4357598.5000\n","Epoch: 95 \tTraining Loss: 28345.4737 \tTraining Accuracy: 9.8577 \tValidation Loss: 218469.7734 \tValidation Accuracy: 9.9316 \ttrain_kl_div: 4357597.5318\n","Epoch: 96 \tTraining Loss: 28345.4623 \tTraining Accuracy: 10.0567 \tValidation Loss: 218469.9838 \tValidation Accuracy: 10.2734 \ttrain_kl_div: 4357597.5000\n","Epoch: 97 \tTraining Loss: 28345.3101 \tTraining Accuracy: 9.8950 \tValidation Loss: 218469.8879 \tValidation Accuracy: 10.2539 \ttrain_kl_div: 4357597.0096\n","Epoch: 98 \tTraining Loss: 42478.5396 \tTraining Accuracy: 9.8154 \tValidation Loss: 218469.6935 \tValidation Accuracy: 9.8926 \ttrain_kl_div: 4357596.5096\n","Epoch: 99 \tTraining Loss: 28345.3454 \tTraining Accuracy: 10.0990 \tValidation Loss: 218469.9102 \tValidation Accuracy: 9.8242 \ttrain_kl_div: 4357596.5000\n"]}]},{"cell_type":"code","source":["!python train_bayesian.py --net_type lenet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYLX1DGbdF0Z","executionInfo":{"status":"ok","timestamp":1651140289471,"user_tz":240,"elapsed":5896,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"9a662578-2701-4427-9805-a7925aa0ab18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"train_bayesian.py\", line 203, in <module>\n","    run(args.dataset, args.net_type)\n","  File \"train_bayesian.py\", line 160, in run\n","    trainset, testset, inputs, outputs = data.getDataset(dataset)\n","TypeError: getDataset() missing 1 required positional argument: 'model'\n"]}]},{"cell_type":"code","source":["!python main_frequentist.py --net_type alexnet --dataset CIFAR10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8DzILiJfSPE","executionInfo":{"status":"ok","timestamp":1651124348948,"user_tz":240,"elapsed":730520,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"c04d6ea7-3208-4902-affb-ffee949262fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100% 157/157 [00:08<00:00, 18.35it/s]\n","100% 40/40 [00:02<00:00, 18.96it/s]\n","Epoch: 1 \tTraining Loss: 448423.3081 \tTraining Accuracy: 7.9020 \tValidation Loss: 2.3051 \tValidation Accuracy: 1.9400\n","Validation loss decreased (inf --> 2.305072).  Saving model ...\n","100% 157/157 [00:08<00:00, 18.08it/s]\n","100% 40/40 [00:02<00:00, 17.87it/s]\n","Epoch: 2 \tTraining Loss: 16.1161 \tTraining Accuracy: 7.9160 \tValidation Loss: 2.3041 \tValidation Accuracy: 2.1420\n","Validation loss decreased (2.305072 --> 2.304127).  Saving model ...\n","100% 157/157 [00:08<00:00, 17.98it/s]\n","100% 40/40 [00:02<00:00, 18.92it/s]\n","Epoch: 3 \tTraining Loss: 2.9924 \tTraining Accuracy: 7.9620 \tValidation Loss: 2.3050 \tValidation Accuracy: 1.9280\n","100% 157/157 [00:08<00:00, 18.35it/s]\n","100% 40/40 [00:02<00:00, 19.06it/s]\n","Epoch: 4 \tTraining Loss: 2.5196 \tTraining Accuracy: 7.9180 \tValidation Loss: 2.3054 \tValidation Accuracy: 1.9940\n","100% 157/157 [00:08<00:00, 18.22it/s]\n","100% 40/40 [00:02<00:00, 18.98it/s]\n","Epoch: 5 \tTraining Loss: 2.4580 \tTraining Accuracy: 7.8280 \tValidation Loss: 2.3038 \tValidation Accuracy: 1.9940\n","Validation loss decreased (2.304127 --> 2.303837).  Saving model ...\n","100% 157/157 [00:08<00:00, 18.12it/s]\n","100% 40/40 [00:02<00:00, 18.77it/s]\n","Epoch: 6 \tTraining Loss: 2.3066 \tTraining Accuracy: 7.7900 \tValidation Loss: 2.3071 \tValidation Accuracy: 1.9980\n","100% 157/157 [00:08<00:00, 18.29it/s]\n","100% 40/40 [00:02<00:00, 18.96it/s]\n","Epoch: 7 \tTraining Loss: 2.3061 \tTraining Accuracy: 7.9240 \tValidation Loss: 2.3036 \tValidation Accuracy: 2.0960\n","Validation loss decreased (2.303837 --> 2.303563).  Saving model ...\n","100% 157/157 [00:08<00:00, 18.21it/s]\n","100% 40/40 [00:02<00:00, 19.37it/s]\n","Epoch: 8 \tTraining Loss: 2.3062 \tTraining Accuracy: 7.9900 \tValidation Loss: 2.3060 \tValidation Accuracy: 1.9940\n","100% 157/157 [00:08<00:00, 17.80it/s]\n","100% 40/40 [00:02<00:00, 19.58it/s]\n","Epoch: 9 \tTraining Loss: 2.3057 \tTraining Accuracy: 8.0740 \tValidation Loss: 2.3094 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.31it/s]\n","100% 40/40 [00:02<00:00, 19.12it/s]\n","Epoch: 10 \tTraining Loss: 11.8039 \tTraining Accuracy: 7.8360 \tValidation Loss: 2.3059 \tValidation Accuracy: 1.9280\n","100% 157/157 [00:08<00:00, 18.37it/s]\n","100% 40/40 [00:02<00:00, 18.94it/s]\n","Epoch: 11 \tTraining Loss: 7.3427 \tTraining Accuracy: 7.9320 \tValidation Loss: 2.3065 \tValidation Accuracy: 1.9980\n","100% 157/157 [00:09<00:00, 17.33it/s]\n","100% 40/40 [00:02<00:00, 18.76it/s]\n","Epoch: 12 \tTraining Loss: 2.4749 \tTraining Accuracy: 8.1040 \tValidation Loss: 2.3105 \tValidation Accuracy: 1.9280\n","100% 157/157 [00:08<00:00, 18.21it/s]\n","100% 40/40 [00:02<00:00, 18.98it/s]\n","Epoch: 13 \tTraining Loss: 2.3069 \tTraining Accuracy: 8.1120 \tValidation Loss: 2.3099 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.48it/s]\n","100% 40/40 [00:02<00:00, 18.78it/s]\n","Epoch 00014: reducing learning rate of group 0 to 1.0000e-02.\n","Epoch: 14 \tTraining Loss: 2.3752 \tTraining Accuracy: 7.8540 \tValidation Loss: 2.3080 \tValidation Accuracy: 1.9940\n","100% 157/157 [00:08<00:00, 18.38it/s]\n","100% 40/40 [00:02<00:00, 18.96it/s]\n","Epoch: 15 \tTraining Loss: 2.3035 \tTraining Accuracy: 7.9380 \tValidation Loss: 2.3028 \tValidation Accuracy: 2.0960\n","Validation loss decreased (2.303563 --> 2.302781).  Saving model ...\n","100% 157/157 [00:08<00:00, 18.14it/s]\n","100% 40/40 [00:02<00:00, 19.02it/s]\n","Epoch: 16 \tTraining Loss: 2.3031 \tTraining Accuracy: 8.1200 \tValidation Loss: 2.3036 \tValidation Accuracy: 1.9280\n","100% 157/157 [00:08<00:00, 18.23it/s]\n","100% 40/40 [00:02<00:00, 18.97it/s]\n","Epoch: 17 \tTraining Loss: 2.3031 \tTraining Accuracy: 7.8160 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.9400\n","100% 157/157 [00:08<00:00, 18.39it/s]\n","100% 40/40 [00:02<00:00, 18.90it/s]\n","Epoch: 18 \tTraining Loss: 9.4410 \tTraining Accuracy: 8.2740 \tValidation Loss: 2.3036 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.31it/s]\n","100% 40/40 [00:02<00:00, 18.94it/s]\n","Epoch: 19 \tTraining Loss: 4.7425 \tTraining Accuracy: 7.7160 \tValidation Loss: 2.3034 \tValidation Accuracy: 1.9940\n","100% 157/157 [00:08<00:00, 18.45it/s]\n","100% 40/40 [00:02<00:00, 19.10it/s]\n","Epoch: 20 \tTraining Loss: 2.3030 \tTraining Accuracy: 7.9100 \tValidation Loss: 2.3038 \tValidation Accuracy: 1.9400\n","100% 157/157 [00:08<00:00, 18.22it/s]\n","100% 40/40 [00:02<00:00, 18.95it/s]\n","Epoch: 21 \tTraining Loss: 2.3031 \tTraining Accuracy: 7.7700 \tValidation Loss: 2.3035 \tValidation Accuracy: 1.9920\n","100% 157/157 [00:08<00:00, 18.35it/s]\n","100% 40/40 [00:02<00:00, 17.96it/s]\n","Epoch 00022: reducing learning rate of group 0 to 1.0000e-03.\n","Epoch: 22 \tTraining Loss: 2.3582 \tTraining Accuracy: 7.7760 \tValidation Loss: 2.3033 \tValidation Accuracy: 2.0260\n","100% 157/157 [00:08<00:00, 18.34it/s]\n","100% 40/40 [00:02<00:00, 19.19it/s]\n","Epoch: 23 \tTraining Loss: 2.3028 \tTraining Accuracy: 8.0300 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.40it/s]\n","100% 40/40 [00:02<00:00, 17.89it/s]\n","Epoch: 24 \tTraining Loss: 2.3027 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.40it/s]\n","100% 40/40 [00:02<00:00, 18.70it/s]\n","Epoch: 25 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.0160 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.57it/s]\n","100% 40/40 [00:02<00:00, 18.73it/s]\n","Epoch: 26 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.38it/s]\n","100% 40/40 [00:02<00:00, 18.85it/s]\n","Epoch: 27 \tTraining Loss: 2.3026 \tTraining Accuracy: 7.8900 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.22it/s]\n","100% 40/40 [00:02<00:00, 18.90it/s]\n","Epoch: 28 \tTraining Loss: 2.3026 \tTraining Accuracy: 7.9080 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.40it/s]\n","100% 40/40 [00:02<00:00, 18.98it/s]\n","Epoch 00029: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch: 29 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.35it/s]\n","100% 40/40 [00:02<00:00, 19.13it/s]\n","Epoch: 30 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.26it/s]\n","100% 40/40 [00:02<00:00, 19.02it/s]\n","Epoch: 31 \tTraining Loss: 10.0244 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.33it/s]\n","100% 40/40 [00:02<00:00, 18.88it/s]\n","Epoch: 32 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 17.50it/s]\n","100% 40/40 [00:02<00:00, 19.21it/s]\n","Epoch: 33 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.13it/s]\n","100% 40/40 [00:02<00:00, 19.66it/s]\n","Epoch: 34 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.59it/s]\n","100% 40/40 [00:02<00:00, 18.99it/s]\n","Epoch: 35 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.58it/s]\n","100% 40/40 [00:02<00:00, 19.13it/s]\n","Epoch 00036: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch: 36 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.79it/s]\n","100% 40/40 [00:02<00:00, 18.24it/s]\n","Epoch: 37 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.56it/s]\n","100% 40/40 [00:02<00:00, 19.05it/s]\n","Epoch: 38 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.82it/s]\n","100% 40/40 [00:02<00:00, 18.99it/s]\n","Epoch: 39 \tTraining Loss: 2.4997 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.59it/s]\n","100% 40/40 [00:02<00:00, 19.12it/s]\n","Epoch: 40 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.63it/s]\n","100% 40/40 [00:02<00:00, 19.10it/s]\n","Epoch: 41 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.65it/s]\n","100% 40/40 [00:02<00:00, 19.67it/s]\n","Epoch: 42 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.92it/s]\n","100% 40/40 [00:02<00:00, 18.85it/s]\n","Epoch 00043: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch: 43 \tTraining Loss: 2.5729 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.62it/s]\n","100% 40/40 [00:02<00:00, 18.85it/s]\n","Epoch: 44 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.63it/s]\n","100% 40/40 [00:02<00:00, 19.26it/s]\n","Epoch: 45 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.45it/s]\n","100% 40/40 [00:02<00:00, 19.01it/s]\n","Epoch: 46 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.62it/s]\n","100% 40/40 [00:02<00:00, 19.33it/s]\n","Epoch: 47 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.49it/s]\n","100% 40/40 [00:02<00:00, 19.35it/s]\n","Epoch: 48 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.35it/s]\n","100% 40/40 [00:02<00:00, 19.50it/s]\n","Epoch: 49 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.61it/s]\n","100% 40/40 [00:02<00:00, 16.79it/s]\n","Epoch 00050: reducing learning rate of group 0 to 1.0000e-07.\n","Epoch: 50 \tTraining Loss: 2.4787 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.72it/s]\n","100% 40/40 [00:02<00:00, 19.16it/s]\n","Epoch: 51 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.22it/s]\n","100% 40/40 [00:02<00:00, 19.03it/s]\n","Epoch: 52 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.63it/s]\n","100% 40/40 [00:02<00:00, 15.73it/s]\n","Epoch: 53 \tTraining Loss: 2.6459 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.70it/s]\n","100% 40/40 [00:02<00:00, 19.40it/s]\n","Epoch: 54 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.78it/s]\n","100% 40/40 [00:02<00:00, 19.54it/s]\n","Epoch: 55 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.51it/s]\n","100% 40/40 [00:02<00:00, 19.06it/s]\n","Epoch: 56 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.52it/s]\n","100% 40/40 [00:02<00:00, 19.26it/s]\n","Epoch 00057: reducing learning rate of group 0 to 1.0000e-08.\n","Epoch: 57 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3029 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.70it/s]\n","100% 40/40 [00:02<00:00, 19.30it/s]\n","Epoch: 58 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.70it/s]\n","100% 40/40 [00:02<00:00, 19.36it/s]\n","Epoch: 59 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.77it/s]\n","100% 40/40 [00:02<00:00, 19.35it/s]\n","Epoch: 60 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.76it/s]\n","100% 40/40 [00:02<00:00, 19.46it/s]\n","Epoch: 61 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3030 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.50it/s]\n","100% 40/40 [00:02<00:00, 19.36it/s]\n","Epoch: 62 \tTraining Loss: 2.3026 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.74it/s]\n","100% 40/40 [00:02<00:00, 19.48it/s]\n","Epoch: 63 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3028 \tValidation Accuracy: 1.8780\n","100% 157/157 [00:08<00:00, 18.70it/s]\n","100% 40/40 [00:02<00:00, 19.37it/s]\n","Epoch: 64 \tTraining Loss: 2.3025 \tTraining Accuracy: 8.1220 \tValidation Loss: 2.3031 \tValidation Accuracy: 1.8780\n","Exception ignored in: <function _releaseLock at 0x7f739918bc20>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n","    def _releaseLock():\n","KeyboardInterrupt\n","  0% 0/157 [00:01<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"main_frequentist.py\", line 191, in <module>\n","^C\n"]}]},{"cell_type":"code","source":["# !pip install tensorboard==2.8.0\n","# !pip uninstall -y tensorboard tb-nightly && pip install tb-nightly \n","# # !python -c \"import mimetypes; print(list(mimetypes.guess_type('index.js')))\"\n","# %load_ext tensorboard\n","# folder=f'alexnet-CIFAR10'\n","# !tensorboard --logdir {folder} --load_fast true \n","file=f'/content/drive/MyDrive/CS690/BayesianPyTorch/lenet-CIFAR10/events.out.tfevents.1651066234.aa3a86bb8394.287.0'\n","!tensorboard --inspect --event_file={f}}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6U3yJEd5ioE","executionInfo":{"status":"ok","timestamp":1651131015051,"user_tz":240,"elapsed":4518,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"6c94e257-e5b2-4c66-97ca-b403b2465193"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","Processing event files... (this can take a few minutes)\n","======================================================================\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n","    sys.exit(run_main())\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/main.py\", line 46, in run_main\n","    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/program.py\", line 276, in main\n","    return runner(self.flags) or 0\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/program.py\", line 289, in _run_serve_subcommand\n","    efi.inspect(flags.logdir, event_file, flags.tag)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/backend/event_processing/event_file_inspector.py\", line 430, in inspect\n","    inspection_units = get_inspection_units(logdir, event_file, tag)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/backend/event_processing/event_file_inspector.py\", line 403, in get_inspection_units\n","    generator = generator_from_event_file(event_file)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/backend/event_processing/event_file_inspector.py\", line 347, in generator_from_event_file\n","    return event_file_loader.LegacyEventFileLoader(event_file).Load()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/backend/event_processing/event_file_loader.py\", line 136, in __init__\n","    self._iterator = _make_tf_record_iterator(self._file_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/backend/event_processing/event_file_loader.py\", line 82, in _make_tf_record_iterator\n","    return tf.compat.v1.io.tf_record_iterator(file_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 357, in new_func\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/tf_record.py\", line 167, in tf_record_iterator\n","    return _pywrap_record_io.RecordIterator(path, compression_type)\n","tensorflow.python.framework.errors_impl.NotFoundError: {f}}; No such file or directory\n"]}]},{"cell_type":"code","source":["import os \n","os.chdir(\"/content/drive/MyDrive/CS690/BayesianPyTorch\")\n","from models.BayesianModels.Bayesian3Conv3FC import BBB3Conv3FC\n","from models.BayesianModels.BayesianAlexNet import BBBAlexNet\n","from models.BayesianModels.BayesianLeNet import BBBLeNet\n","from models.NonBayesianModels.AlexNet import AlexNet\n","from models.NonBayesianModels.LeNet import LeNet\n","from models.NonBayesianModels.ThreeConvThreeFC import ThreeConvThreeFC\n","import data\n","import utils\n","import metrics\n","import config_frequentist as cfg\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","from torch.optim import Adam, lr_scheduler\n","!pip install torchattacks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCfxyKiVoYEg","executionInfo":{"status":"ok","timestamp":1651112779621,"user_tz":240,"elapsed":17586,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"7a73f324-4a60-4d09-d358-6009997d4677"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchattacks\n","  Downloading torchattacks-3.2.6-py3-none-any.whl (105 kB)\n","\u001b[?25l\r\u001b[K     |                             | 10 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |                         | 20 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |                      | 30 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |                   | 40 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |                | 51 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |             | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |          | 71 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |       | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |    | 92 kB 8.2 MB/s eta 0:00:01\r\u001b[K     | | 102 kB 9.0 MB/s eta 0:00:01\r\u001b[K     || 105 kB 9.0 MB/s \n","\u001b[?25hInstalling collected packages: torchattacks\n","Successfully installed torchattacks-3.2.6\n"]}]},{"cell_type":"code","source":["from torchattacks import PGD"],"metadata":{"id":"p6B5SZPIfra1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"s8ga-kdnQ-Dt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getModel(net_type, inputs, outputs):\n","    if (net_type == 'lenet'):\n","        return LeNet(outputs, inputs)\n","    elif (net_type == 'alexnet'):\n","        return AlexNet(outputs, inputs)\n","    elif (net_type == '3conv3fc'):\n","        return ThreeConvThreeFC(outputs, inputs)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","\n","def test_model(net, criterion, test_loader):\n","    valid_loss = 0.0\n","    net.eval()\n","    accs = []\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = net(data)\n","        loss = criterion(output, target)\n","        valid_loss += loss.item()*data.size(0)\n","        accs.append(metrics.acc(output.detach(), target))\n","    return valid_loss, np.mean(accs)\n"],"metadata":{"id":"LdZ9-FhgR7oX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net_type = \"lenet\"\n","dataset = \"MNIST\"\n","n_epochs = cfg.n_epochs\n","lr = cfg.lr\n","num_workers = cfg.num_workers\n","valid_size = cfg.valid_size\n","batch_size = cfg.batch_size\n","criterion = nn.CrossEntropyLoss()\n"],"metadata":{"id":"M6cYKh0hVaRJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainset, testset, inputs, outputs = data.getDataset(dataset)\n","train_loader, valid_loader, test_loader = data.getDataloader(\n","        trainset, testset, valid_size, batch_size, num_workers)\n","model = getModel(net_type, inputs, outputs).to(device)\n","\n","ckpt_dir = f'checkpoints/{dataset}/frequentist'\n","ckpt_name = f'checkpoints/{dataset}/frequentist/model_{net_type}.pt'\n","model.load_state_dict(torch.load(ckpt_name))\n","model = model.eval().cuda()\n","optimizer = Adam(model.parameters(), lr=lr)\n","lr_sched = lr_scheduler.ReduceLROnPlateau(optimizer, patience=6, verbose=True)\n","atk = PGD(model, eps=8/255, alpha=2/255, steps=7)\n","atk.set_return_type('int') # Save as integer.\n","atk.save(data_loader=test_loader, save_path=\"/content/drive/MyDrive/CS690/BayesianPyTorch/adv_data/mnist_pgd.pt\", verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"1FXK8fBwSRx8","executionInfo":{"status":"error","timestamp":1650878675348,"user_tz":240,"elapsed":185,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"5b3aac79-b217-4d06-f6dd-16e375043dd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-34e14133581a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loader, valid_loader, test_loader = data.getDataloader(\n\u001b[1;32m      3\u001b[0m         trainset, testset, valid_size, batch_size, num_workers)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mckpt_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'checkpoints/{dataset}/frequentist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: getModel() missing 3 required positional arguments: 'priors', 'layer_type', and 'activation_type'"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"nNTT4qZeXFEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loss, test_acc = test_model(model, criterion, test_loader)\n","\n","test_loss = test_loss/len(test_loader.dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfmtfJRMWWVV","executionInfo":{"status":"ok","timestamp":1650787643222,"user_tz":240,"elapsed":1717,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"9d49b408-522b-4f12-dd2e-bbbf85b28cae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["print(test_loss)\n","print(test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bsRC1pBbQ5O","executionInfo":{"status":"ok","timestamp":1650787670246,"user_tz":240,"elapsed":8,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"aaef62a8-0ec0-4f4c-8b22-a10505f94422"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.2484176315844059\n","0.95185546875\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","adv_images, adv_labels = torch.load(\"/content/drive/MyDrive/CS690/BayesianPyTorch/adv_data/mnist_pgd.pt\")\n","adv_data = TensorDataset(adv_images.float()/255, adv_labels)\n","adv_loader = DataLoader(adv_data, batch_size=cfg.batch_size, shuffle=False)"],"metadata":{"id":"LzOcLuHBcSVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adv_loss, adv_acc = test_model(model, criterion, adv_loader)\n","\n","adv_loss = adv_loss/len(adv_loader.dataset)\n","print(adv_loss)\n","print(adv_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5vyWn8gciaT","executionInfo":{"status":"ok","timestamp":1650787714275,"user_tz":240,"elapsed":385,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"7cf00e20-d71f-4e7b-965e-cbbf2f1bbe1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.514749061203003\n","0.20703125\n"]}]},{"cell_type":"code","source":["from torch.nn import functional as F\n","\n","def BPGD(model, criterion, len, image,labels, eps=0.3, alpha=2/255, iters=40,num_ens=1) :\n","    # images = images.to(device)\n","    # labels = labels.to(device)\n","    # loss = nn.CrossEntropyLoss()\n","        \n","    # ori_images = images.data\n","    training_loss = 0.0\n","    accs = []\n","    kl_list = []\n","    for i in range(iters) :  \n","          inputs= image.to(device)\n","          labels=labels.to(device)\n","          outputs = torch.zeros(inputs.shape[0], model.num_classes, num_ens).to(device)\n","          inputs.requires_grad = True\n","          kl = 0.0\n","          for j in range(num_ens):\n","              net_out, _kl = model(inputs)\n","              kl += _kl\n","              outputs[:, :, j] = F.log_softmax(net_out, dim=1)\n","          \n","          kl = kl / num_ens\n","          kl_list.append(kl.item())\n","          log_outputs = utils.logmeanexp(outputs, dim=2)\n","\n","          beta = 1/ len\n","          loss = criterion(log_outputs, labels, kl, beta)\n","          loss.backward()\n","          inputs = inputs + alpha*inputs.grad.sign()\n","          eta = torch.clamp(adv_images - inputs, min=-eps, max=eps)\n","          inputs = torch.clamp(inputs + eta, min=0, max=1).detach_()\n","    return inputs\n","\n","    # for i in range(iters) :    \n","    #     images.requires_grad = True\n","    #     outputs = model(images)\n","\n","    #     model.zero_grad()\n","    #     cost = loss(outputs, labels).to(device)\n","    #     cost.backward()\n","\n","    #     adv_images = images + alpha*images.grad.sign()\n","    #     eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n","    #     images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n","            \n","    # return images"],"metadata":{"id":"Q3SwX6Jrrd9U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import config_bayesian as cfg2\n","\n","def getModel(net_type, inputs, outputs, priors, layer_type, activation_type):\n","    if (net_type == 'lenet'):\n","        return BBBLeNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == 'alexnet'):\n","        return BBBAlexNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == '3conv3fc'):\n","        return BBB3Conv3FC(outputs, inputs, priors, layer_type, activation_type)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","net_type = \"lenet\"\n","dataset = \"MNIST\"\n","layer_type = cfg2.layer_type\n","activation_type = cfg2.activation_type\n","priors = cfg2.priors\n","criterion = metrics.ELBO(len(test_loader)).to(device)\n","\n","train_ens = cfg2.train_ens\n","valid_ens = cfg2.valid_ens\n","n_epochs = cfg2.n_epochs\n","lr_start = cfg2.lr_start\n","num_workers = cfg2.num_workers\n","valid_size = cfg2.valid_size\n","batch_size = cfg2.batch_size\n","beta_type = cfg2.beta_type\n","\n","trainset, testset, inputs, outputs = data.getDataset(dataset)\n","train_loader, valid_loader, test_loader = data.getDataloader(\n","        trainset, testset, valid_size, batch_size, num_workers)\n","\n","model2 = getModel(net_type, inputs, outputs, priors, layer_type, activation_type).to(device)\n","\n","ckpt_dir = f'checkpoints/{dataset}/bayesian'\n","ckpt_name = f'checkpoints/{dataset}/bayesian/model_{net_type}_{layer_type}_{activation_type}.pt'\n","\n","model2.load_state_dict(torch.load(ckpt_name))\n","model2 = model2.eval().cuda()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"McxIL-Y3nfFt","executionInfo":{"status":"ok","timestamp":1650879831726,"user_tz":240,"elapsed":273,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"bb703bcb-10ac-4278-ee03-598dc39e95c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["\n","correct = 0\n","total = 0\n","\n","\n","for images, labels in test_loader:\n","    model2.train()\n","    btest_loss=0.0\n","    btest_accs=[]\n","    adv_images = BPGD(model2,criterion,len(test_loader),images,labels, eps=8/255, alpha=2/255, iters=100)\n","    labels = labels.to(device)\n","    outputs = torch.zeros(adv_images.shape[0], model2.num_classes, 1).to(device)\n","    kl = 0.0\n","    for j in range(1):\n","        net_out, _kl = model2(adv_images)\n","        kl += _kl\n","        outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n","\n","    log_outputs = utils.logmeanexp(outputs, dim=2)\n","\n","    criterion = metrics.ELBO(len(test_loader)).to(device)\n","    \n","    beta = 1/ len(test_loader)\n","    btest_loss += criterion(log_outputs, labels, kl, beta).item()\n","    btest_accs.append(metrics.acc(log_outputs, labels))\n","\n","print( btest_loss/len(test_loader), np.mean(btest_accs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"04_th1Qyvho-","executionInfo":{"status":"error","timestamp":1650879835995,"user_tz":240,"elapsed":657,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"1ed20dd2-e4a0-48ee-8d7b-d260d303048e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-0f1830a6e08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbtest_accs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-626903a2f5b0>\u001b[0m in \u001b[0;36mBPGD\u001b[0;34m(model, criterion, len, image, labels, eps, alpha, iters, num_ens)\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m           \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_images\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (256) at non-singleton dimension 0"]}]},{"cell_type":"code","source":["!python testadv_b --dataset MNIST --attack PGD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hz0bOUWGRkKi","executionInfo":{"status":"ok","timestamp":1650801476812,"user_tz":240,"elapsed":875,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"8f1edf9b-ab01-4397-8b72-0388ab1245cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file 'testadv_b': [Errno 2] No such file or directory\n"]}]},{"cell_type":"code","source":["# !pip install torchattacks\n","import pkg_resources\n","import subprocess\n","import sys\n","import os\n","\n","REQUIRED = {\n","  'spacy', 'scikit-learn', 'numpy', 'pandas', 'torch', \n","  'torchattacks', 'matplotlib'\n","}\n","\n","installed = {pkg.key for pkg in pkg_resources.working_set}\n","missing = REQUIRED - installed\n","\n","if missing:\n","    python = sys.executable\n","    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n","\n","import sys\n","\n","sys.path.insert(0, \"/content/drive/MyDrive/CS690/BayesianPyTorch\") # to include ../helper_evaluate.py etc.\n","\n","\n","import os \n","# os.chdir(\"/content/\")\n","from torch.nn import functional as F\n","\n","from models.BayesianModels.Bayesian3Conv3FC import BBB3Conv3FC\n","from models.BayesianModels.BayesianAlexNet import BBBAlexNet\n","from models.BayesianModels.BayesianLeNet import BBBLeNet\n","from models.NonBayesianModels.AlexNet import AlexNet\n","from models.NonBayesianModels.LeNet import LeNet\n","from models.NonBayesianModels.ThreeConvThreeFC import ThreeConvThreeFC\n","\n","import os.path\n","import data\n","import utils\n","import metrics\n","\n","import config_bayesian as cfg2\n","import config_frequentist as cfg\n","\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import matplotlib.pyplot as plt\n","from torchattacks import PGD, FGSM\n","import gzip,tarfile\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def getBModel(net_type, inputs, outputs, priors, layer_type, activation_type):\n","    if (net_type == 'lenet'):\n","        return BBBLeNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == 'alexnet'):\n","        return BBBAlexNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == '3conv3fc'):\n","        return BBB3Conv3FC(outputs, inputs, priors, layer_type, activation_type)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","def getFModel(net_type, inputs, outputs):\n","    if (net_type == 'lenet'):\n","        return LeNet(outputs, inputs)\n","    elif (net_type == 'alexnet'):\n","        return AlexNet(outputs, inputs)\n","    elif (net_type == '3conv3fc'):\n","        return ThreeConvThreeFC(outputs, inputs)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","def validate_model(net, criterion, validloader, num_ens=1, beta_type=0.1):\n","    \"\"\"Calculate ensemble accuracy and NLL Loss\"\"\"\n","    net.train()\n","    valid_loss = 0.0\n","    accs = []\n","\n","    for i, (inputs, labels) in enumerate(validloader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n","        kl = 0.0\n","        for j in range(num_ens):\n","            net_out, _kl = net(inputs)\n","            kl += _kl\n","            outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n","\n","        log_outputs = utils.logmeanexp(outputs, dim=2)\n","\n","        beta = 1/len(validloader)\n","        valid_loss += criterion(log_outputs, labels, kl, beta).item()\n","        accs.append(metrics.acc(log_outputs, labels))\n","\n","    return valid_loss/len(validloader), np.mean(accs)\n","\n","def test_model(net, criterion, test_loader):\n","    valid_loss = 0.0\n","    net.eval()\n","    accs = []\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = net(data)\n","        loss = criterion(output, target)\n","        valid_loss += loss.item()*data.size(0)\n","        accs.append(metrics.acc(output.detach(), target))\n","    return valid_loss, np.mean(accs)\n","    \n","def BPGD(model, criterion, len, image,labels, eps=0.3, alpha=2/255, iters=40,num_ens=1) :\n","    # images = images.to(device)\n","    # labels = labels.to(device)\n","    # loss = nn.CrossEntropyLoss()\n","        \n","    # ori_images = images.data\n","    training_loss = 0.0\n","    accs = []\n","    kl_list = []\n","    for i in range(iters) :  \n","          inputs= image.to(device)\n","          labels=labels.to(device)\n","          outputs = torch.zeros(inputs.shape[0], model.num_classes, num_ens).to(device)\n","          inputs.requires_grad = True\n","          kl = 0.0\n","          for j in range(num_ens):\n","              net_out, _kl = model(inputs)\n","              kl += _kl\n","              outputs[:, :, j] = F.log_softmax(net_out, dim=1)\n","          \n","          kl = kl / num_ens\n","          kl_list.append(kl.item())\n","          log_outputs = utils.logmeanexp(outputs, dim=2)\n","\n","          beta = 1/ len\n","          loss = criterion(log_outputs, labels, kl, beta)\n","          loss.backward()\n","          adv_images = inputs + alpha*inputs.grad.sign()\n","          eta = torch.clamp(adv_images - inputs, min=-eps, max=eps)\n","          images = torch.clamp(inputs + eta, min=0, max=1).detach_()\n","    return images\n","\n","def test_attack_freq(freq,dataset,test_loader,inputs,outputs,attack):\n","    # n_epochs = cfg.n_epochs\n","    attack_dir=f'adv_data/frequentist/{attack}'\n","    battack_dir=f'adv_data/bayesian/{attack}'\n","\n","    if not os.path.exists(attack_dir):\n","      os.makedirs(attack_dir)\n","    if not os.path.exists(battack_dir):\n","      os.makedirs(battack_dir)\n","    lr = cfg.lr\n","\n","    criterion = nn.CrossEntropyLoss()\n","    dict={}\n","    \n","    for model in freq:\n","        fmodel = getFModel(model, inputs, outputs).to(device)\n","        ckpt_name = f'checkpoints/{dataset}/frequentist/model_{model}.pt'\n","        fmodel.load_state_dict(torch.load(ckpt_name))\n","        fmodel = fmodel.eval().cuda()\n","        test_loss, test_acc = test_model(fmodel, criterion, test_loader)\n","        # for step in range(0,100,10):\n","        # print(\"freq - \",model)\n","        pgdstep=[]\n","        accuracies=[]\n","        for eps in range(0,11,1): \n","            epsilon=np.round(eps*0.05, 2)\n","            badv_dir=f'adv_data/frequentist/{attack}/{dataset}_{model}_{epsilon}_{attack}.pt.tar'\n","            if attack=='PGD':\n","              atk = PGD(fmodel, eps=epsilon, alpha=lr, steps=20)\n","            if attack=='FGSM':\n","              atk= FGSM(fmodel, eps=epsilon)\n","            if attack=='BIM':\n","              atk = BIM(fmodel, eps=epsilon, alpha=lr, steps=20)\n","            if attack=='PGDL2':\n","              atk = PGDL2(fmodel, eps=epsilon, alpha=15/255, steps=10, random_start=False)\n","            atk.set_return_type('int') # Save as integer.\n","            adv_dir=f'adv_data/bayesian/{attack}/{dataset}_{model}_{epsilon}_{attack}.pt.tar'\n","            if not os.path.exists(adv_dir):\n","              atk.save(data_loader=test_loader, save_path=adv_dir, verbose=False)\n","              atk.save(data_loader=test_loader, save_path=badv_dir, verbose=False)\n","            # test_loss = test_loss/len(test_loader.dataset)\n","            \n","            adv_images, adv_labels = torch.load(adv_dir)\n","            adv_data = TensorDataset(adv_images.float()/255, adv_labels)\n","            adv_loader = DataLoader(adv_data, batch_size=cfg.batch_size, shuffle=False)\n","            adv_loss, adv_acc = test_model(fmodel, criterion, adv_loader)\n","            pgdstep.append(epsilon)\n","            accuracies.append(adv_acc)\n","            # print(\"Step\", step, \"Accuracy\", adv_acc)\n","            \n","        dict[model]={\"accu\":accuracies, 'epsilon':pgdstep}\n","    return dict       \n","def test_attack_bayes(bay,dataset,test_loader,inputs,outputs,attack):\n","    layer_type = cfg2.layer_type\n","    activation_type = cfg2.activation_type\n","    priors = cfg2.priors\n","    criterion = metrics.ELBO(len(test_loader)).to(device)\n","\n","    train_ens = cfg2.train_ens\n","    valid_ens = cfg2.valid_ens\n","    n_epochs = cfg2.n_epochs\n","    lr_start = cfg2.lr_start\n","    num_workers = cfg2.num_workers\n","    valid_size = cfg2.valid_size\n","    batch_size = cfg2.batch_size\n","    beta_type = cfg2.beta_type\n","    \n","    # valid_size = cfg2.valid_size\n","    # batch_size = cfg2.batch_size\n","    \n","    # trainset, testset, inputs, outputs = data.getDataset(dataset)\n","    # train_loader, valid_loader, test_loader = data.getDataloader(\n","    #         trainset, testset, valid_size, batch_size, num_workers)\n","    dict={}\n","    for model in bay:\n","        # print(\"Bay - \",model)\n","        ckpt_name = f'checkpoints/{dataset}/bayesian/model_{model[1:]}_{layer_type}_{activation_type}.pt'\n","        # print(ckpt_name)\n","        bmodel = getBModel(model[1:], inputs, outputs, priors, layer_type, activation_type).to(device)\n","    \n","        # ckpt_dir = f'checkpoints/{dataset}/bayesian'\n","        bmodel.load_state_dict(torch.load(ckpt_name))\n","        bmodel = bmodel.eval().cuda()\n","        pgdstep=[]\n","        accuracies=[] \n","        # for step in [40]: \n","        for eps in range(0,11,1):  \n","            # adv_dir=f'adv_data/frequentist/{dataset}_{model[1:]}_{step}_PGD.pt'\n","            epsilon=np.round(eps*0.05,2)\n","            adv_dir=f'adv_data/bayesian/{attack}/{dataset}_{model[1:]}_{epsilon}_{attack}.pt.tar'\n","            if os.path.exists(adv_dir):\n","            # atk.save(data_loader=test_loader, save_path=adv_dir, verbose=True)\n","            # test_loss = test_loss/len(test_loader.dataset)\n","              adv_images, adv_labels = torch.load(adv_dir)\n","              adv_data = TensorDataset(adv_images.float()/255, adv_labels)\n","              adv_loader = DataLoader(adv_data, batch_size=cfg.batch_size, shuffle=False)\n","              adv_loss, adv_acc =  validate_model(bmodel, criterion, adv_loader, num_ens=valid_ens, beta_type=beta_type)\n","              pgdstep.append(epsilon)\n","              accuracies.append(adv_acc)\n","            # print(\"Step\", step, \"Accuracy\", adv_acc)\n","        dict[model]={\"accu\":accuracies, 'epsilon':pgdstep}\n","    return dict\n","        #     correct = 0\n","        #     total = 0\n","        #     for images, labels in test_loader:\n","        #         # model2.train()\n","        #         # btest_loss=0.0\n","        #         # btest_accs=[]\n","        #         # adv_images = BPGD(model2,criterion,len(test_loader),images,labels, eps=0.03, alpha=cfg.lr, iters=step)\n","        #         # labels = labels.to(device)\n","        #         adv_images, adv_labels = torch.load(adv_dir)\n","        #         adv_data = TensorDataset(adv_images.float()/255, adv_labels)\n","        #         adv_loader = DataLoader(adv_data, batch_size=cfg.batch_size, shuffle=False)\n","        #         adv_loss, adv_acc = test_model(fmodel, criterion, adv_loader)\n","        #         pgdstep.append(step)\n","        #         accuracies.append(adv_acc)\n","        #         print(\"Step\", step, \"Accuracy\". adv_acc)\n","        #         # outputs = torch.zeros(adv_images.shape[0], model2.num_classes, 1).to(device)\n","        #         # kl = 0.0\n","        #         # for j in range(1):\n","        #         #     net_out, _kl = model2(adv_images)\n","        #         #     kl += _kl\n","        #         #     outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n","            \n","        #         # log_outputs = utils.logmeanexp(outputs, dim=2)\n","            \n","        #         # criterion = metrics.ELBO(len(test_loader)).to(device)\n","                \n","        #         # beta = 1/ len(test_loader)\n","        #         # btest_loss += criterion(log_outputs, labels, kl, beta).item()\n","        #         # btest_accs.append(metrics.acc(log_outputs, labels))\n","            \n","        #     pgdstep.append(step)\n","        #     accuracies.append(np.mean(btest_accs))\n","        # dict[model]={\"accu\":accuracies, 'steps':pgdstep}\n","           \n","\n","def plot_PGD(dic_1,dic_2,attack,dataset):\n","    \n","    fmodels= dic_1.keys() \n","    bmodels= dic_2.keys()\n","    for f in fmodels:\n","        dic=dic_1[f]\n","        x=dic['epsilon']\n","        y=dic['accu']\n","        # print(f,y)\n","        plt.plot(x, y, label=f, marker='o')\n","        \n","    for b in bmodels:\n","        dic=dic_2[b]\n","        x=dic['epsilon']\n","        y=dic['accu']\n","        plt.plot(x, y, label=b, marker='v')\n","    title=f'{dataset} - {attack} epsilon'\n","    save=f'/content/drive/MyDrive/CS690/BayesianPyTorch/att_figure/{dataset}_{attack}_epsilon.png'\n","    plt.title(title)\n","    plt.legend(loc='upper right', frameon=False)\n","    plt.xlabel('Epsilon')\n","    plt.ylabel('Test Accuracy')\n","    plt.savefig(save)\n","        \n","def test(dataset,attack):\n","    freq=[]\n","    bay=[]\n","    layer_type = cfg2.layer_type\n","    activation_type = cfg2.activation_type\n","    for model in ['alexnet','lenet']:\n","        fckpt_name = f'checkpoints/{dataset}/frequentist/model_{model}.pt'\n","        bckpt_name = f'checkpoints/{dataset}/bayesian/model_{model}_{layer_type}_{activation_type}.pt'\n","        if os.path.exists(fckpt_name):\n","            freq.append(model)\n","        if os.path.exists(bckpt_name):\n","            bay.append('B'+model)\n","    \n","    valid_size = cfg.valid_size\n","    batch_size = cfg.batch_size\n","    num_workers = cfg.num_workers\n","    \n","    trainset, testset, inputs, outputs = data.getDataset(dataset,'alexnet')\n","    train_loader, valid_loader, test_loader = data.getDataloader(trainset, testset, valid_size, batch_size, num_workers)\n","    \n","\n","    dict_1 = dict_2 = {}\n","    dict_1=test_attack_freq(freq,dataset,test_loader,inputs,outputs,attack)\n","    dict_2=test_attack_bayes(bay,dataset,test_loader,inputs,outputs,attack)\n","    plot_PGD(dict_1,dict_2,attack,dataset)\n","\n","    # if attack=='FGSM':\n","    #     dict_1 = dict_2 = {}\n","    #     dict_1=test_attack_PGD_freq(freq,dataset,test_loader,inputs,outputs)\n","    #     dict_2=test_attack_PGD_bayes(bay,dataset,test_loader,inputs,outputs)\n","    #     plot_PGD(dict_1,dict_2)\n","    \n","# if __name__ == '__main__':\n","#     parser = argparse.ArgumentParser(description = \"Test Gradient-Based attack\")\n","#     parser.add_argument('--dataset', default='MNIST', type=str, help='dataset = [MNIST/CIFAR10]')\n","#     parser.add_argument('--attack',default='PGD', type=str, help='attack = [PGD/FGSM]')\n","#     args = parser.parse_args()\n","    \n","# test('MNIST','FGSM')\n","test('MNIST','PGD')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"n3p0OkiG2ItP","executionInfo":{"status":"ok","timestamp":1652657450725,"user_tz":-330,"elapsed":3421,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"7644ffcf-5d25-486a-dd3d-f9bae68a9671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","No handles with labels found to put in legend.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["\n","import os \n","os.chdir(\"/content/drive/MyDrive/CS690/BayesianPyTorch\")\n","from torch.nn import functional as F\n","\n","from models.BayesianModels.Bayesian3Conv3FC import BBB3Conv3FC\n","from models.BayesianModels.BayesianAlexNet import BBBAlexNet\n","from models.BayesianModels.BayesianLeNet import BBBLeNet\n","from models.NonBayesianModels.AlexNet import AlexNet\n","from models.NonBayesianModels.LeNet import LeNet\n","from models.NonBayesianModels.ThreeConvThreeFC import ThreeConvThreeFC\n","\n","import os.path\n","import data\n","import utils\n","import metrics\n","\n","import config_bayesian as cfg2\n","import config_frequentist as cfg\n","\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import matplotlib.pyplot as plt\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def getBModel(net_type, inputs, outputs, priors, layer_type, activation_type):\n","    if (net_type == 'lenet'):\n","        return BBBLeNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == 'alexnet'):\n","        return BBBAlexNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == '3conv3fc'):\n","        return BBB3Conv3FC(outputs, inputs, priors, layer_type, activation_type)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","def getFModel(net_type, inputs, outputs):\n","    if (net_type == 'lenet'):\n","        return LeNet(outputs, inputs)\n","    elif (net_type == 'alexnet'):\n","        return AlexNet(outputs, inputs)\n","    elif (net_type == '3conv3fc'):\n","        return ThreeConvThreeFC(outputs, inputs)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","def validate_model(net, criterion, validloader, num_ens=1, beta_type=0.1):\n","    \"\"\"Calculate ensemble accuracy and NLL Loss\"\"\"\n","    net.train()\n","    valid_loss = 0.0\n","    accs = []\n","\n","    for i, (inputs, labels) in enumerate(validloader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n","        kl = 0.0\n","        for j in range(num_ens):\n","            net_out, _kl = net(inputs)\n","            kl += _kl\n","            outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n","\n","        log_outputs = utils.logmeanexp(outputs, dim=2)\n","\n","        beta = 1/len(validloader)\n","        valid_loss += criterion(log_outputs, labels, kl, beta).item()\n","        accs.append(metrics.acc(log_outputs, labels))\n","\n","    return valid_loss/len(validloader), np.mean(accs)\n","\n","def test_model(net, criterion, test_loader):\n","    valid_loss = 0.0\n","    net.eval()\n","    accs = []\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = net(data)\n","        loss = criterion(output, target)\n","        valid_loss += loss.item()*data.size(0)\n","        accs.append(metrics.acc(output.detach(), target))\n","    return valid_loss, np.mean(accs)\n","    \n","def BPGD(model, criterion, len, image,labels, eps=0.3, alpha=2/255, iters=40,num_ens=1) :\n","    training_loss = 0.0\n","    accs = []\n","    kl_list = []\n","    for i in range(iters) :  \n","          inputs= image.to(device)\n","          labels=labels.to(device)\n","          outputs = torch.zeros(inputs.shape[0], model.num_classes, num_ens).to(device)\n","          inputs.requires_grad = True\n","          kl = 0.0\n","          for j in range(num_ens):\n","              net_out, _kl = model(inputs)\n","              kl += _kl\n","              outputs[:, :, j] = F.log_softmax(net_out, dim=1)\n","          \n","          kl = kl / num_ens\n","          kl_list.append(kl.item())\n","          log_outputs = utils.logmeanexp(outputs, dim=2)\n","\n","          beta = 1/ len\n","          loss = criterion(log_outputs, labels, kl, beta)\n","          loss.backward()\n","          adv_images = inputs + alpha*inputs.grad.sign()\n","          eta = torch.clamp(adv_images - inputs, min=-eps, max=eps)\n","          images = torch.clamp(inputs + eta, min=0, max=1).detach_()\n","    return images\n","\n","def test_attack_freq(freq,dataset,test_loader,inputs,outputs):\n","  \n","    lr = cfg.lr\n","\n","    criterion = nn.CrossEntropyLoss()\n","    dict={}\n","    \n","    for model in freq:\n","        fmodel = getFModel(model, inputs, outputs).to(device)\n","        ckpt_name = f'checkpoints/{dataset}/frequentist/model_{model}.pt'\n","        fmodel.load_state_dict(torch.load(ckpt_name))\n","        fmodel = fmodel.eval().cuda()\n","        test_loss, test_acc = test_model(fmodel, criterion, test_loader)\n","        dict[model]={\"accu\":test_acc, 'model':model}\n","    return dict       \n","def test_attack_bayes(bay,dataset,test_loader,inputs,outputs):\n","    layer_type = cfg2.layer_type\n","    activation_type = cfg2.activation_type\n","    priors = cfg2.priors\n","    criterion = metrics.ELBO(len(test_loader)).to(device)\n","\n","    train_ens = cfg2.train_ens\n","    valid_ens = cfg2.valid_ens\n","    n_epochs = cfg2.n_epochs\n","    lr_start = cfg2.lr_start\n","    num_workers = cfg2.num_workers\n","    valid_size = cfg2.valid_size\n","    batch_size = cfg2.batch_size\n","    beta_type = cfg2.beta_type\n","  \n","    dict={}\n","    for model in bay:\n","        ckpt_name = f'checkpoints/{dataset}/bayesian/model_{model[1:]}_{layer_type}_{activation_type}.pt'\n","        bmodel = getBModel(model[1:], inputs, outputs, priors, layer_type, activation_type).to(device)\n","    \n","        bmodel.load_state_dict(torch.load(ckpt_name))\n","        bmodel = bmodel.eval().cuda()\n","        test_loss, test_acc =validate_model(bmodel, criterion, test_loader, num_ens=valid_ens, beta_type=beta_type) \n","        dict[model]={\"accu\":test_acc, 'model':model}\n","    return dict\n","\n","def plot_PGD(dic_1,dic_2,dataset):\n","    fig = plt.figure(figsize = (10, 5))\n","    fmodels= dic_1.keys() \n","    bmodels= dic_2.keys()\n","    for f in fmodels:\n","        dic=dic_1[f]\n","        x=dic['model']\n","        y=dic['accu']\n","        # print(f,y)\n","        plt.bar(x, y, width = 0.4)\n","        \n","    for b in bmodels:\n","        dic=dic_2[b]\n","        x=dic['model']\n","        y=dic['accu']\n","        plt.bar(x, y, width = 0.4)\n","\n","    title=f'{dataset} - Test Accuracies'\n","    save=f'/content/drive/MyDrive/CS690/BayesianPyTorch/att_figure/{dataset}_Test_Accuracies.png'\n","    plt.xlabel(\"Model\")\n","    plt.ylabel(\"Test Accuracy\")\n","    plt.title(title)\n","    # plt.show()\n","    plt.savefig(save)\n","        \n","def test(dataset):\n","    freq=[]\n","    bay=[]\n","    layer_type = cfg2.layer_type\n","    activation_type = cfg2.activation_type\n","    for model in ['alexnet','lenet','3conv3fc']:\n","        fckpt_name = f'checkpoints/{dataset}/frequentist/model_{model}.pt'\n","        bckpt_name = f'checkpoints/{dataset}/bayesian/model_{model}_{layer_type}_{activation_type}.pt'\n","        if os.path.exists(fckpt_name):\n","            freq.append(model)\n","        if os.path.exists(bckpt_name):\n","            bay.append('B'+model)\n","    \n","    valid_size = cfg.valid_size\n","    batch_size = cfg.batch_size\n","    num_workers = cfg.num_workers\n","    \n","    trainset, testset, inputs, outputs = data.getDataset(dataset,'alexnet')\n","    train_loader, valid_loader, test_loader = data.getDataloader(trainset, testset, valid_size, batch_size, num_workers)    \n","\n","    dict_1 = dict_2 = {}\n","    dict_1=test_attack_freq(freq,dataset,test_loader,inputs,outputs)\n","    dict_2=test_attack_bayes(bay,dataset,test_loader,inputs,outputs)\n","    plot_PGD(dict_1,dict_2,dataset)\n","    \n","# if __name__ == '__main__':\n","#     parser = argparse.ArgumentParser(description = \"Test Gradient-Based attack\")\n","#     parser.add_argument('--dataset', default='MNIST', type=str, help='dataset = [MNIST/CIFAR10]')\n","#     parser.add_argument('--attack',default='PGD', type=str, help='attack = [PGD/FGSM]')\n","#     args = parser.parse_args()\n","    \n","# test('MNIST','FGSM')\n","test('CIFAR10')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"5fMwIyXYTZpi","executionInfo":{"status":"ok","timestamp":1652664689326,"user_tz":-330,"elapsed":22290,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"c95e7dd9-c693-46f7-f175-9ab027416d73"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["!python test_acc.py --dataset MNIST"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdDWcGjoGRp-","executionInfo":{"status":"ok","timestamp":1652658130365,"user_tz":-330,"elapsed":34132,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"2a7b9695-ddf5-4a71-f922-cab2325fa8fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters initialized\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["!pip install torchinfo\n","import os \n","from torchsummary import summary\n","import torch\n","os.chdir(\"/content/drive/MyDrive/CS690/BayesianPyTorch\")\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def getBModel(net_type, inputs, outputs, priors, layer_type, activation_type):\n","    if (net_type == 'lenet'):\n","        return BBBLeNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == 'alexnet'):\n","        return BBBAlexNet(outputs, inputs, priors, layer_type, activation_type)\n","    elif (net_type == '3conv3fc'):\n","        return BBB3Conv3FC(outputs, inputs, priors, layer_type, activation_type)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","def getFModel(net_type, inputs, outputs):\n","    if (net_type == 'lenet'):\n","        return LeNet(outputs, inputs)\n","    elif (net_type == 'alexnet'):\n","        return AlexNet(outputs, inputs)\n","    elif (net_type == '3conv3fc'):\n","        return ThreeConvThreeFC(outputs, inputs)\n","    else:\n","        raise ValueError('Network should be either [LeNet / AlexNet / 3Conv3FC')\n","\n","for model in ['alexnet','lenet','3conv3fc']:\n","        freq=[]\n","        bay=[]\n","        layer_type = cfg2.layer_type\n","        activation_type = cfg2.activation_type\n","        fckpt_name = f'checkpoints/CIFAR10/frequentist/model_{model}.pt'\n","        bckpt_name = f'checkpoints/CIFAR10/bayesian/model_{model}_lrt_{activation_type}.pt'\n","        if os.path.exists(fckpt_name):\n","            freq.append(model)\n","        if os.path.exists(bckpt_name):\n","            bay.append('B'+model)\n","        # for model in freq:\n","        #   ckpt_name = f'checkpoints/CIFAR10/frequentist/model_{model}.pt'\n","        #   fmodel = getFModel(model, 3, 10).to(device)\n","        #   fmodel.load_state_dict(torch.load(ckpt_name))\n","        #   print(fmodel)\n","        layer_type = cfg2.layer_type\n","        activation_type = cfg2.activation_type\n","        priors = cfg2.priors\n","        criterion = metrics.ELBO(10).to(device)\n","\n","        train_ens = cfg2.train_ens\n","        valid_ens = cfg2.valid_ens\n","        n_epochs = cfg2.n_epochs\n","        lr_start = cfg2.lr_start\n","        num_workers = cfg2.num_workers\n","        valid_size = cfg2.valid_size\n","        batch_size = cfg2.batch_size\n","        beta_type = cfg2.beta_type\n","        \n","        # valid_size = cfg2.valid_size\n","        # batch_size = cfg2.batch_size\n","        \n","        # trainset, testset, inputs, outputs = data.getDataset(dataset)\n","        # train_loader, valid_loader, test_loader = data.getDataloader(\n","        #         trainset, testset, valid_size, batch_size, num_workers)\n","        dict={}\n","        for model in freq:\n","            fmodel = getFModel(model, 1, 10).to(device)\n","            ckpt_name = f'checkpoints/MNIST/frequentist/model_{model}.pt'\n","            fmodel.load_state_dict(torch.load(ckpt_name))\n","            summary(fmodel, (1, 32, 32))\n","        # print(bay)\n","        # for model in ['lenet']:\n","        #     # print(\"Bay - \",model)\n","        #     ckpt_name = f'checkpoints/MNIST/bayesian/model_{model[1:]}_lrt_{activation_type}.pt'\n","        #     # print(ckpt_name)\n","        #     bmodel = getBModel(model[1:], 3, 10, priors, layer_type, activation_type).to(device)\n","        #     batch_size = 256\n","        #     summary(bmodel, input_size=(3, 32, 32))\n","        #     # ckpt_dir = f'checkpoints/{dataset}/bayesian'\n","        #     print(bmodel)\n","            # summary(bmodel, (3, 32, 32))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNwVeoOJZNwA","executionInfo":{"status":"ok","timestamp":1651887978029,"user_tz":240,"elapsed":7338,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"d67766e7-f5ef-4752-d0ce-2498d1acd8ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.6.5)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1             [-1, 64, 8, 8]           7,808\n","              ReLU-2             [-1, 64, 8, 8]               0\n","              ReLU-3             [-1, 64, 8, 8]               0\n","           Dropout-4             [-1, 64, 8, 8]               0\n","         MaxPool2d-5             [-1, 64, 4, 4]               0\n","            Conv2d-6            [-1, 192, 4, 4]         307,392\n","              ReLU-7            [-1, 192, 4, 4]               0\n","              ReLU-8            [-1, 192, 4, 4]               0\n","         MaxPool2d-9            [-1, 192, 2, 2]               0\n","           Conv2d-10            [-1, 384, 2, 2]         663,936\n","             ReLU-11            [-1, 384, 2, 2]               0\n","             ReLU-12            [-1, 384, 2, 2]               0\n","          Dropout-13            [-1, 384, 2, 2]               0\n","           Conv2d-14            [-1, 256, 2, 2]         884,992\n","             ReLU-15            [-1, 256, 2, 2]               0\n","             ReLU-16            [-1, 256, 2, 2]               0\n","           Conv2d-17            [-1, 256, 2, 2]         590,080\n","             ReLU-18            [-1, 256, 2, 2]               0\n","             ReLU-19            [-1, 256, 2, 2]               0\n","          Dropout-20            [-1, 256, 2, 2]               0\n","        MaxPool2d-21            [-1, 256, 1, 1]               0\n","           Linear-22                   [-1, 10]           2,570\n","================================================================\n","Total params: 2,456,778\n","Trainable params: 2,456,778\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.31\n","Params size (MB): 9.37\n","Estimated Total Size (MB): 9.69\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 28, 28]             156\n","            Conv2d-2           [-1, 16, 10, 10]           2,416\n","            Linear-3                  [-1, 120]          48,120\n","            Linear-4                   [-1, 84]          10,164\n","            Linear-5                   [-1, 10]             850\n","================================================================\n","Total params: 61,706\n","Trainable params: 61,706\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.05\n","Params size (MB): 0.24\n","Estimated Total Size (MB): 0.29\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 32, 32]             832\n","          Softplus-2           [-1, 32, 32, 32]               0\n","          Softplus-3           [-1, 32, 32, 32]               0\n","          Softplus-4           [-1, 32, 32, 32]               0\n","         MaxPool2d-5           [-1, 32, 15, 15]               0\n","            Conv2d-6           [-1, 64, 15, 15]          51,264\n","          Softplus-7           [-1, 64, 15, 15]               0\n","          Softplus-8           [-1, 64, 15, 15]               0\n","          Softplus-9           [-1, 64, 15, 15]               0\n","        MaxPool2d-10             [-1, 64, 7, 7]               0\n","           Conv2d-11            [-1, 128, 5, 5]         204,928\n","         Softplus-12            [-1, 128, 5, 5]               0\n","         Softplus-13            [-1, 128, 5, 5]               0\n","         Softplus-14            [-1, 128, 5, 5]               0\n","        MaxPool2d-15            [-1, 128, 2, 2]               0\n","     FlattenLayer-16                  [-1, 512]               0\n","           Linear-17                 [-1, 1000]         513,000\n","         Softplus-18                 [-1, 1000]               0\n","         Softplus-19                 [-1, 1000]               0\n","         Softplus-20                 [-1, 1000]               0\n","           Linear-21                 [-1, 1000]       1,001,000\n","         Softplus-22                 [-1, 1000]               0\n","         Softplus-23                 [-1, 1000]               0\n","         Softplus-24                 [-1, 1000]               0\n","           Linear-25                   [-1, 10]          10,010\n","================================================================\n","Total params: 1,781,034\n","Trainable params: 1,781,034\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.68\n","Params size (MB): 6.79\n","Estimated Total Size (MB): 8.48\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["from torch.nn import Parameter\n","Parameter(torch.Tensor(5,4,*(3,3)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FVZvy1yyzZO","executionInfo":{"status":"ok","timestamp":1651495478817,"user_tz":240,"elapsed":96,"user":{"displayName":"Sowmya Iyer","userId":"01034242328399791880"}},"outputId":"1f3afcfe-11ac-48d0-a045-8531f4dd0e51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[[[ 1.6892e-34,  0.0000e+00, -9.3279e+35],\n","          [ 4.5853e-41, -8.9325e+35,  4.5853e-41],\n","          [-3.5393e+35,  4.5853e-41, -3.1077e+35]],\n","\n","         [[ 4.5853e-41, -1.6265e+34,  4.5853e-41],\n","          [-1.0999e+34,  4.5853e-41, -1.3268e+34],\n","          [ 4.5853e-41, -3.5962e+35,  4.5853e-41]],\n","\n","         [[-3.5730e+35,  4.5853e-41, -4.6126e+35],\n","          [ 4.5853e-41, -5.2147e+35,  4.5853e-41],\n","          [-3.2041e+35,  4.5853e-41, -1.2473e+34]],\n","\n","         [[ 4.5853e-41, -1.2431e+34,  4.5853e-41],\n","          [-5.4015e+35,  4.5853e-41, -4.3975e+35],\n","          [ 4.5853e-41, -1.2241e+34,  4.5853e-41]]],\n","\n","\n","        [[[-1.3288e+34,  4.5853e-41, -9.9751e+35],\n","          [ 4.5853e-41, -5.3159e+35,  4.5853e-41],\n","          [-3.5546e+35,  4.5853e-41, -1.2071e+34]],\n","\n","         [[ 4.5853e-41, -3.5541e+35,  4.5853e-41],\n","          [-3.5654e+35,  4.5853e-41, -3.5378e+35],\n","          [ 4.5853e-41, -5.1207e+35,  4.5853e-41]],\n","\n","         [[-3.5652e+35,  4.5853e-41, -5.0381e+35],\n","          [ 4.5853e-41, -5.1334e+35,  4.5853e-41],\n","          [-5.0378e+35,  4.5853e-41, -3.3146e+35]],\n","\n","         [[ 4.5853e-41, -5.1197e+35,  4.5853e-41],\n","          [-3.4037e+35,  4.5853e-41, -3.7056e+35],\n","          [ 4.5853e-41, -3.6564e+35,  4.5853e-41]]],\n","\n","\n","        [[[-3.2013e+35,  4.5853e-41, -3.3992e+35],\n","          [ 4.5853e-41, -3.4210e+35,  4.5853e-41],\n","          [-3.4213e+35,  4.5853e-41, -4.4468e+35]],\n","\n","         [[ 4.5853e-41, -8.7810e+35,  4.5853e-41],\n","          [-1.1150e+34,  4.5853e-41, -9.1549e+35],\n","          [ 4.5853e-41, -4.4833e+35,  4.5853e-41]],\n","\n","         [[-4.4846e+35,  4.5853e-41, -4.3007e+35],\n","          [ 4.5853e-41, -1.9923e+30,  4.5853e-41],\n","          [-3.9362e+35,  4.5853e-41, -4.5294e+35]],\n","\n","         [[ 4.5853e-41, -4.2852e+35,  4.5853e-41],\n","          [-4.2848e+35,  4.5853e-41, -3.4175e+35],\n","          [ 4.5853e-41, -4.0999e+35,  4.5853e-41]]],\n","\n","\n","        [[[-9.8846e+35,  4.5853e-41, -1.8650e+30],\n","          [ 4.5853e-41, -4.0251e+35,  4.5853e-41],\n","          [-4.9185e+35,  4.5853e-41, -4.2840e+35]],\n","\n","         [[ 4.5853e-41, -4.0988e+35,  4.5853e-41],\n","          [-4.6949e+35,  4.5853e-41,  9.4102e-02],\n","          [ 4.5853e-41,  9.4469e-02,  4.5853e-41]],\n","\n","         [[ 9.4101e-02,  4.5853e-41,  9.4101e-02],\n","          [ 4.5853e-41,  9.3284e-02,  4.5853e-41],\n","          [ 9.4473e-02,  4.5853e-41, -4.0249e+35]],\n","\n","         [[ 4.5853e-41, -3.5540e+10,  4.5855e-41],\n","          [ 9.1312e-02,  4.5853e-41,  9.1320e-02],\n","          [ 4.5853e-41,  9.4100e-02,  4.5853e-41]]],\n","\n","\n","        [[[ 9.4862e-02,  4.5853e-41,  9.1979e-02],\n","          [ 4.5853e-41,  9.4467e-02,  4.5853e-41],\n","          [ 9.1969e-02,  4.5853e-41,  9.4229e-02]],\n","\n","         [[ 4.5853e-41,  9.4099e-02,  4.5853e-41],\n","          [ 9.4756e-02,  4.5853e-41,  9.1319e-02],\n","          [ 4.5853e-41,  9.4478e-02,  4.5853e-41]],\n","\n","         [[ 9.4102e-02,  4.5853e-41, -3.5622e+10],\n","          [ 4.5855e-41,  9.4869e-02,  4.5853e-41],\n","          [ 8.8186e-02,  4.5853e-41,  9.2727e-02]],\n","\n","         [[ 4.5853e-41,  9.0745e-02,  4.5853e-41],\n","          [ 8.8008e-02,  4.5853e-41,  0.0000e+00],\n","          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], requires_grad=True)"]},"metadata":{},"execution_count":89}]}]}